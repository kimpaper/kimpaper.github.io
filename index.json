[{"content":"맥북에어 m2에서 겪었던 현상.\n아카이브 유틸리티 동작이 안되는 현상 왜 그러는지는 모르겠지만, zip을 클릭했을때 압축이 안풀리는 현상이 있었다 이유를 보니\n숫자가 앞에 있었다.\n1_test.zip 압축이 풀리지 않음 test.zip 압축풀림\n이름을 변경하니 더블클릭으로 압축이 풀렸다.\n1_test.zip 압축풀기 메뉴를 눌러 폴더 선택을 직접 하면 풀린다.\n연속 압축으로 인식한껄까.\n","permalink":"https://kimpaper.github.io/posts/mac/2023-04-08-%EC%95%84%EC%B9%B4%EC%9D%B4%EB%B8%8C%EC%9C%A0%ED%8B%B8%EB%A6%AC%ED%8B%B0-%EB%8F%99%EC%9E%91-%EC%95%88%EB%90%98%EB%8A%94-%ED%98%84%EC%83%81/","summary":"맥북에어 m2에서 겪었던 현상.\n아카이브 유틸리티 동작이 안되는 현상 왜 그러는지는 모르겠지만, zip을 클릭했을때 압축이 안풀리는 현상이 있었다 이유를 보니\n숫자가 앞에 있었다.\n1_test.zip 압축이 풀리지 않음 test.zip 압축풀림\n이름을 변경하니 더블클릭으로 압축이 풀렸다.\n1_test.zip 압축풀기 메뉴를 눌러 폴더 선택을 직접 하면 풀린다.\n연속 압축으로 인식한껄까.","title":"아카이브유틸리티 동작 안되는 현상"},{"content":"http prof 를 이용해 프로파일 한다 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import ( \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; ) func main() { go func() { log.Println(http.ListenAndServe(\u0026#34;0.0.0.0:6060\u0026#34;, nil)) }() ... do somthing ... } cpu profile (30초동안 데이터를 모은다) 1 go tool pprof http://xxxx:6060/debug/pprof/profile heap memory (현재 메모리 정보를 반환한다) 1 go tool pprof http://xxxx:6060/debug/pprof/heap heap 을 실행하면 아래와 같이 command line (pprof)가 나오는데 프로파일 명령을 넣으면 된다. 가령 web 을 치면 윈도우에 경우 web 브라우저에 메모리 Map이 나온다 1 2 3 4 5 6 7 8 Fetching profile over HTTP from http://xxxx:6060/debug/pprof/heap Saved profile in C:\\Users\\Paper\\pprof\\pprof.xxxx.alloc_objects.alloc_space.inuse_objects.inuse_space.013.pb.gz File: xxxx Build ID: 8028feec58a6d0902dc3f3c6e08c6ce789b01028 Type: inuse_space Time: Apr 3, 2022 at 12:17pm (KST) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) web web 명령을 사용하려면 Graphviz 라는 프로그램을 설치해놔야 한다. Graphviz ","permalink":"https://kimpaper.github.io/posts/golang/2022-03-28-golang_profiler/","summary":"http prof 를 이용해 프로파일 한다 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import ( \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; ) func main() { go func() { log.Println(http.ListenAndServe(\u0026#34;0.0.0.0:6060\u0026#34;, nil)) }() ... do somthing ... } cpu profile (30초동안 데이터를 모은다) 1 go tool pprof http://xxxx:6060/debug/pprof/profile heap memory (현재 메모리 정보를 반환한다) 1 go tool pprof http://xxxx:6060/debug/pprof/heap heap 을 실행하면 아래와 같이 command line (pprof)가 나오는데 프로파일 명령을 넣으면 된다.","title":"golang profiler 사용"},{"content":"kubernetes 에서 ingress 상에서 https를 서비스하는데 지원을 해주는 좋은.. 모듈\ncert manager 설치 (1) 참고 https://cert-manager.io/docs/installation/kubernetes/\n1 2 kubectl create namespace cert-manager kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.13.1/cert-manager.yaml cert manager 설치 (with helm) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $ kubectl apply --validate=false -f https://raw.githubusercontent.com/jetstack/cert-manager/v0.13.1/deploy/manifests/00-crds.yaml $ kubectl create namespace cert-manager $ helm repo add jetstack https://charts.jetstack.io $ helm repo update # Helm v3+ $ helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --version v0.13.1 # Helm v2 $ helm install \\ --name cert-manager \\ --namespace cert-manager \\ --version v0.13.1 \\ jetstack/cert-manager 설치 확인 1 kubectl get pods --namespace cert-manager 사실 내용 자체는 https://cert-manager.io/docs/installation/kubernetes/ 사이트를 보고 그대로 따라했다. 중요한건 staging 과 prod가 나뉘어 있다는거고, Issuer 와 ClusterIssuer 가 구분되어 있다는건데 Issuer는 namespace간 발급이 안되므로, 가능하면 ClusterIssuer를 사용하자 staging 는 환경 테스트에만 사용하고, 성공하면 prod로 바꾸어서 실제 인증서를 발급받아야 한다. cert manager issuser example email: test@test.com 부분을 실제 email로 교체하라 다른 부분은 건들 부분이 크게 없다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-staging spec: acme: # The ACME server URL server: https://acme-staging-v02.api.letsencrypt.org/directory # Email address used for ACME registration email: test@test.com # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-staging # Enable the HTTP-01 challenge provider solvers: # An empty \u0026#39;selector\u0026#39; means that this solver matches all domains - selector: {} http01: ingress: class: nginx --- apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-prod spec: acme: # The ACME server URL server: https://acme-v02.api.letsencrypt.org/directory # Email address used for ACME registration email: test@test.com # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-prod # Enable the HTTP-01 challenge provider solvers: - http01: ingress: class: nginx kubernetes-dashboard에 적용 www.test.com; 부분을 원하는 도메인으로 바꾼다. 발급 테스트가 완료되면 cert-manager.io/cluster-issuer: \u0026quot;letsencrypt-staging\u0026quot;\ncert-manager.io/cluster-issuer: \u0026quot;letsencrypt-prod\u0026quot;\n로 바꾸어 실제 인증서를 발급 받는다. 주의사항이 있는데 아래 annotoations 에서 nginx.ingress.kubernetes.io/backend-protocol: HTTPS 는 kubernetes/nginx-ingress 에서만 된다. nginx/nginx-ingress 는.. 안된다. 주의하자 (ingress를 다른거 설치해서 굉장히 삽질했다.) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 kind: Ingress apiVersion: extensions/v1beta1 metadata: name: kubernetes-dashboard namespace: kubernetes-dashboard labels: app: kubernetes-dashboard annotations: kubernetes.io/ingress.class: nginx cert-manager.io/cluster-issuer: \u0026#34;letsencrypt-staging\u0026#34; nginx.ingress.kubernetes.io/backend-protocol: HTTPS spec: tls: - hosts: - www.test.com secretName: www-test-com-tls rules: - host: www.test.com http: paths: - path: / backend: serviceName: kubernetes-dashboard servicePort: 443 status: loadBalancer: ingress: - {} 삽질 과정에서 내부망과 외부망의 도메인 접근이 바뀌어서 고생했는데 일반적인 환경에서는 크게 무리 없을것 같다. (저걸 구축할때 내부망 dns를 사용하는 바람에 실제 verify가 되지 않아 고생했으나 나중에 눈치채고 dns ip를 외부로 바꾸니 잘된다.) 확인.. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 [root@kube1 11]# kubectl describe certificate -n nginx-ingress Name: www.test.com Namespace: nginx-ingress Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; API Version: cert-manager.io/v1alpha2 Kind: Certificate Metadata: Creation Timestamp: 2020-03-13T06:02:23Z Generation: 1 Owner References: API Version: extensions/v1beta1 Block Owner Deletion: true Controller: true Kind: Ingress Name: www.test.com UID: a7d05229-a8cb-405a-80f7-424b0d00a71b Resource Version: 44540390 Self Link: /apis/cert-manager.io/v1alpha2/namespaces/nginx-ingress/certificates/$$$$$$$$$ UID: 2e762fbc-2111-4b72-ae75-319f8d018be9 Spec: Dns Names: www.test.com Issuer Ref: Group: cert-manager.io Kind: ClusterIssuer Name: letsencrypt-prod Secret Name: ########### Status: Conditions: Last Transition Time: 2020-03-13T06:03:27Z Message: Certificate is up to date and has not expired Reason: Ready Status: True Type: Ready Not After: 2020-06-11T05:03:26Z Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Requested 52s cert-manager Created new CertificateRequest resource \u0026#34;cgitlab-p-exem-xyz-3450475095\u0026#34; Normal Issued \u0026lt;invalid\u0026gt; cert-manager Certificate issued successfully Normal Issued \u0026lt;invalid\u0026gt; cert-manager Certificate issued successfully successfully가 뜨면 성공이다. ","permalink":"https://kimpaper.github.io/2020/05/13/kubernetes-certmanager/","summary":"kubernetes 에서 ingress 상에서 https를 서비스하는데 지원을 해주는 좋은.. 모듈\ncert manager 설치 (1) 참고 https://cert-manager.io/docs/installation/kubernetes/\n1 2 kubectl create namespace cert-manager kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.13.1/cert-manager.yaml cert manager 설치 (with helm) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $ kubectl apply --validate=false -f https://raw.githubusercontent.com/jetstack/cert-manager/v0.13.1/deploy/manifests/00-crds.yaml $ kubectl create namespace cert-manager $ helm repo add jetstack https://charts.jetstack.io $ helm repo update # Helm v3+ $ helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --version v0.","title":"kubernetes cert-manager"},{"content":"glusterfs-kubernetes 설치 시도 중 gluster-kubernetes/deploy/gk-deploy 파일을 열어서 아래 라인을 고쳐야 한다 (kubectl에 없어진 인자값을 쓴다)\n1 2 3 # deprecated \u0026#34;--show-all\u0026#34; parameter #heketi_pod=$(${CLI} get pod --no-headers --show-all --selector=\u0026#34;heketi\u0026#34; | awk \u0026#39;{print $1}\u0026#39;) heketi_pod=$(${CLI} get pod --no-headers --selector=\u0026#34;heketi\u0026#34; | awk \u0026#39;{print $1}\u0026#39;) 1 2 3 4 5 6 7 8 9 # daemonset을 설치하기 위해 # 노드별로 아래 경로를 비워야함 rm -rf /var/lib/misc/glusterfsd /var/lib/glusterd /var/log/glusterfs /etc/glusterfs /var/lib/heketi #uninstall ./gk-deploy -g --user-key userkey --admin-key adminkey -n glusterfs --abort #install ./gk-deploy -g --user-key userkey --admin-key adminkey -n glusterfs 신규 glusterfs 노드가 추가될때 topology.json을 수정하고 1 heketi-cli topology load --json=to.json --user admin --secret adminkey 1 2 디스크 확인 lsblk lvm 관련 도움말\nhttps://3sikkim.tistory.com/7\n설치시 disk가 사용중이라고 나오면 아래와 같이 싹 날려\u0026hellip;버려 1 2 3 4 5 6 vgdispaly vgremove vg_{Dlkjsdfljsdfljsdf} lsof | grep LogVol01 fuser -kuc /dev/VolGroup00/LogVol01 디스크가 사용중이라 vg_가 삭제 안되면 재부팅, 그전에 아래 명령으로 disk가 마운트되어 있지 않은지 확인해야 한다. (마운트를 해제하지 않으면 재부팅이 안됨) 1 cat /etc/fstab 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # # /etc/fstab # Created by anaconda on Thu Sep 20 14:48:48 2018 # # Accessible filesystems, by reference, are maintained under \u0026#39;/dev/disk\u0026#39; # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=952140d5-6d1b-476b-b26d-aa8442633148 /boot xfs defaults 0 0 UUID=34FE-0D05 /boot/efi vfat umask=0077,shortname=winnt 0 0 /dev/mapper/centos-home /home xfs defaults 0 0 #/dev/mapper/centos-swap swap swap defaults 0 0 #/dev/sda1 /home2 xfs defaults 0 0 #gluster00:gfs /glusterfs glusterfs defaults,_netdev 0 0 topology.json샘플 \u0026ldquo;destroyData\u0026rdquo;: true 이건 좀 위험 빼고 싶지만 다시 설치가 너무 힘들다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 { \u0026#34;clusters\u0026#34;: [ { \u0026#34;nodes\u0026#34;: [ { \u0026#34;node\u0026#34;: { \u0026#34;hostnames\u0026#34;: { \u0026#34;manage\u0026#34;: [ \u0026#34;kube3\u0026#34; ], \u0026#34;storage\u0026#34;: [ \u0026#34;10.10.31.146\u0026#34; ] }, \u0026#34;zone\u0026#34;: 1 }, \u0026#34;devices\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;/dev/sda\u0026#34; , \u0026#34;destroyData\u0026#34;: true } ] }, { \u0026#34;node\u0026#34;: { \u0026#34;hostnames\u0026#34;: { \u0026#34;manage\u0026#34;: [ \u0026#34;kube4\u0026#34; ], \u0026#34;storage\u0026#34;: [ \u0026#34;10.10.31.152\u0026#34; ] }, \u0026#34;zone\u0026#34;: 1 }, \u0026#34;devices\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;/dev/sdb\u0026#34; , \u0026#34;destroyData\u0026#34;: true } ] }, { \u0026#34;node\u0026#34;: { \u0026#34;hostnames\u0026#34;: { \u0026#34;manage\u0026#34;: [ \u0026#34;kube5\u0026#34; ], \u0026#34;storage\u0026#34;: [ \u0026#34;10.10.31.153\u0026#34; ] }, \u0026#34;zone\u0026#34;: 1 }, \u0026#34;devices\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;/dev/sda\u0026#34; , \u0026#34;destroyData\u0026#34;: true } ] }, { \u0026#34;node\u0026#34;: { \u0026#34;hostnames\u0026#34;: { \u0026#34;manage\u0026#34;: [ \u0026#34;kube6\u0026#34; ], \u0026#34;storage\u0026#34;: [ \u0026#34;10.10.32.191\u0026#34; ] }, \u0026#34;zone\u0026#34;: 1 }, \u0026#34;devices\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;/dev/sdb\u0026#34; , \u0026#34;destroyData\u0026#34;: true } ] }, { \u0026#34;node\u0026#34;: { \u0026#34;hostnames\u0026#34;: { \u0026#34;manage\u0026#34;: [ \u0026#34;kube7\u0026#34; ], \u0026#34;storage\u0026#34;: [ \u0026#34;10.10.32.192\u0026#34; ] }, \u0026#34;zone\u0026#34;: 1 }, \u0026#34;devices\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;/dev/sdb\u0026#34; , \u0026#34;destroyData\u0026#34;: true } ] } ] } ] } secrets 에서 heketi-config-secret 에서 초기 deploy 용 config 같다. 아래는 json을 base64로 인코딩한 값들이다. 실제로 설치에 성공했다면 glusterfs pv를 이용하여 마운트가 되므로 사용하지 않을것이다. (증명은 못해봄) 1 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 StorageClass - glusterfs 1 2 3 4 5 6 7 8 9 10 11 12 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: glusterfs provisioner: kubernetes.io/glusterfs parameters: resturl: \u0026#34;http://{heketi.gluserfs.svc의 Endpoint ip}:8080\u0026#34; restauthenabled: \u0026#34;true\u0026#34; restuser: \u0026#34;admin\u0026#34; restuserkey: \u0026#34;adminkey\u0026#34; volumetype: \u0026#34;none\u0026#34; allowVolumeExpansion: false \u0026ldquo;http://{heketi.gluserfs.svc의 Endpoint ip}:8080\u0026rdquo; 를 할때 kubernetes dns 를 이용하면 안된다. restfurl에 service 의 clusterip를 넣어도 되는걸 확인 endpoint 아이피는 바뀔 위험이 있다. 대체 어디서 query를 하길래 안되는거냐 volumetype은 저장 방식에 대한 설명인데. replicate:3 인 경우 3개 복제, disperse:4:2 면 4개 데이터 복구를 위한 데이터2 총 6개 브릭 사용 (브릭은 저장단위 블럭같은거다) 아니면 none으로 한다 이건 1개에 그냥 저장하나. 이런 경우에 해당 volume가 망가지면 복구가 힘들다 replicate와 disperse 에 단점은 replicate 는 당연히 저장 공간이 곱절로 든다는 것이다. 1 \u0026#39;Replica volume\u0026#39;: volumetype: replicate:3 where \u0026#39;3\u0026#39; is replica count. \u0026#39;Disperse/EC volume\u0026#39;: volumetype: disperse:4:2 where \u0026#39;4\u0026#39; is data and \u0026#39;2\u0026#39; is the redundancy count. \u0026#39;Distribute volume\u0026#39;: volumetype: none 실제 복구 과정에서 삽질의 하나였지만, 사실 reset을 하지 않으면 아래는 필요가 없다. 1 2 3 4 5 6 7 8 9 10 gluster volume delete vol_3cb6e6973ef6366616bad693996ce444 gluster volume delete vol_3fbc9aee403388863f32709f09579de0 gluster volume delete vol_7bde0724f9cb828789293b6b28f29bcf gluster volume delete vol_8059e09dd2a2b476966d73517ffc694c gluster volume delete vol_81c09d96d88ac7c5f17341192c59b727 gluster volume delete vol_9301d3846066104602682e59c8cb6c8a gluster volume delete vol_a06486abbe89c848a0081fb2221860e8 gluster volume delete vol_b16f85e4353566f4760f02e9dbf527db gluster volume delete vol_becbc87401a29c01554fbced7c7feb17 gluster volume delete vol_c353b5987ddd55903b81c0ffa20e6120 ","permalink":"https://kimpaper.github.io/posts/kube/2020-05-13-kubernetes-glusterfs/","summary":"glusterfs-kubernetes 설치 시도 중 gluster-kubernetes/deploy/gk-deploy 파일을 열어서 아래 라인을 고쳐야 한다 (kubectl에 없어진 인자값을 쓴다)\n1 2 3 # deprecated \u0026#34;--show-all\u0026#34; parameter #heketi_pod=$(${CLI} get pod --no-headers --show-all --selector=\u0026#34;heketi\u0026#34; | awk \u0026#39;{print $1}\u0026#39;) heketi_pod=$(${CLI} get pod --no-headers --selector=\u0026#34;heketi\u0026#34; | awk \u0026#39;{print $1}\u0026#39;) 1 2 3 4 5 6 7 8 9 # daemonset을 설치하기 위해 # 노드별로 아래 경로를 비워야함 rm -rf /var/lib/misc/glusterfsd /var/lib/glusterd /var/log/glusterfs /etc/glusterfs /var/lib/heketi #uninstall ./gk-deploy -g --user-key userkey --admin-key adminkey -n glusterfs --abort #install .","title":"kubernetes glusterfs 연동"},{"content":" 외부로 ingress를 노출하고 처리하는 서버가 kubernetes 내에 service가 아니라 다른 별도의 서버일 경우에 아래와 같이 proxy_pass를 지정한다. (사실 응용하면 nginx 기능들이 지원하는건 다 될것 같다.) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 kind: Ingress apiVersion: extensions/v1beta1 metadata: name: gitlab.test.com namespace: nginx-ingress annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/proxy-connect-timeout: \u0026#39;3600\u0026#39; nginx.ingress.kubernetes.io/proxy-read-timeout: \u0026#39;3600\u0026#39; nginx.ingress.kubernetes.io/proxy-send-timeout: \u0026#39;3600\u0026#39; nginx.ingress.kubernetes.io/send-timeout: \u0026#39;3600\u0026#39; nginx.ingress.kubernetes.io/server-snippet: | location ~ / { proxy_pass http://10.10.10.101:8084; } spec: rules: - host: gitlab.test.com http: paths: - path: / backend: serviceName: nginx-ingress-default-backend servicePort: 8080 status: loadBalancer: ingress: - {} 위에 serviceName 은 실제로 사용하는 서비스가 아니라 dummy 서비스이다. annotations을 추가하는 이유는 websocket 때문이다.(websocket 안쓰면 없어도 됨) 1 2 3 4 nginx.ingress.kubernetes.io/proxy-connect-timeout: \u0026#39;3600\u0026#39; nginx.ingress.kubernetes.io/proxy-read-timeout: \u0026#39;3600\u0026#39; nginx.ingress.kubernetes.io/proxy-send-timeout: \u0026#39;3600\u0026#39; nginx.ingress.kubernetes.io/send-timeout: \u0026#39;3600\u0026#39; ","permalink":"https://kimpaper.github.io/2020/05/13/kubernetes-ingress-urlproxy/","summary":"외부로 ingress를 노출하고 처리하는 서버가 kubernetes 내에 service가 아니라 다른 별도의 서버일 경우에 아래와 같이 proxy_pass를 지정한다. (사실 응용하면 nginx 기능들이 지원하는건 다 될것 같다.) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 kind: Ingress apiVersion: extensions/v1beta1 metadata: name: gitlab.test.com namespace: nginx-ingress annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/proxy-connect-timeout: \u0026#39;3600\u0026#39; nginx.ingress.kubernetes.io/proxy-read-timeout: \u0026#39;3600\u0026#39; nginx.","title":"kubernetes ingress - 특정 url로 proxy 걸기"},{"content":"macOS 에서 ssh key를 지정하여 서버로 비밀번호 타이핑 없이 바로 로그인 하게 하자\n평소엔 보안때문에 안해놓는다.\nmacOS - 키 생성 1 ssh-keygen -t rsa -C \u0026#34;name\u0026#34; - public key를 조회 1 cat ~/.ssh/id_rsa.pub 대상 Server (CentOS) - public key를 ~/.ssh/authorized_keys 파일에 추가 1 vi ~/.ssh/authorized_keys ","permalink":"https://kimpaper.github.io/posts/centos/2016-08-11-ssh-key-login/","summary":"macOS 에서 ssh key를 지정하여 서버로 비밀번호 타이핑 없이 바로 로그인 하게 하자\n평소엔 보안때문에 안해놓는다.\nmacOS - 키 생성 1 ssh-keygen -t rsa -C \u0026#34;name\u0026#34; - public key를 조회 1 cat ~/.ssh/id_rsa.pub 대상 Server (CentOS) - public key를 ~/.ssh/authorized_keys 파일에 추가 1 vi ~/.ssh/authorized_keys ","title":"ssh key를 이용한 로그인"},{"content":"Redis Data Type 요약 인터넷상에 수많은 좋은 자료가 있음에도 공부 차원에서 정리를 한다\n테스트는 redis-cli를 이용해서 하지만 실제 사용은 언어에 맞는 api library를 사용 할듯\n개요 http://redis.io/topics/data-types-intro\n예제 http://redis.io/topics/data-types\nStrings value에 문자 숫자 등을 저장한다 저장시 별도로 형이 없다 (숫자 문자 구분이 없음) 숫자도 저장가능 하다 그리고 숫자에 incr, incrby, decr, decrby 같은 atomic counter 연산이 가능 incrby, decrby 는 특정 수를 더하거나 뺄때 사용 incrby \u0026quot;test_strings\u0026quot; 10 처럼 사용 1 2 3 4 5 6 7 8 9 10 # redis-cli 127.0.0.1:6379\u0026gt; set \u0026#34;test_strings\u0026#34; 1 OK 127.0.0.1:6379\u0026gt; get \u0026#34;test_strings\u0026#34; \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; incr \u0026#34;test_strings\u0026#34; (integer) 2 127.0.0.1:6379\u0026gt; get \u0026#34;test_strings\u0026#34; \u0026#34;2\u0026#34; 127.0.0.1:6379\u0026gt; Lists value에 list를 저장한다 lrange: 값을 조회 이때 -1은 모두 가져오라는 뜻 1 2 3 4 5 6 7 8 9 10 11 127.0.0.1:6379\u0026gt; lpush \u0026#34;test_lists\u0026#34; 1 127.0.0.1:6379\u0026gt; lpush test_lists 2 127.0.0.1:6379\u0026gt; lrange test_lists 0 -1 1) \u0026#34;2\u0026#34; 2) \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; rpush test_lists 3 (integer) 3 127.0.0.1:6379\u0026gt; lrange test_lists 0 -1 1) \u0026#34;2\u0026#34; 2) \u0026#34;1\u0026#34; 3) \u0026#34;3\u0026#34; rpop를 이용하여 queue 구현이 가능할꺼 같다 1 2 3 4 5 127.0.0.1:6379\u0026gt; rpop test_lists \u0026#34;3\u0026#34; 127.0.0.1:6379\u0026gt; lrange test_lists 0 -1 1) \u0026#34;2\u0026#34; 2) \u0026#34;1\u0026#34; rbpop을 이용하면 순차적인 분산 작업도 구현 가능할꺼 같다 rpop과 비슷하나 데이타가 없다면 데이타가 들어올때까지 block 상태로 대기한다 Sets value을 set형태로 가지고 있음 list는 중복이 되나 set은 중복이 안됨 1 2 3 4 5 6 7 8 9 10 11 127.0.0.1:6379\u0026gt; sadd test_sets 1 (integer) 1 127.0.0.1:6379\u0026gt; smembers test_sets 1) \u0026#34;1\u0026#34; 127.0.0.1:6379\u0026gt; sadd test_sets 1 2 3 4 (integer) 3 127.0.0.1:6379\u0026gt; smembers test_sets 1) \u0026#34;1\u0026#34; 2) \u0026#34;2\u0026#34; 3) \u0026#34;3\u0026#34; 4) \u0026#34;4\u0026#34; Hashes Hashs key/value 목록을 값으로 가진다 1 2 3 4 5 6 7 8 9 10 11 127.0.0.1:6379\u0026gt; hset htest username hi (integer) 1 127.0.0.1:6379\u0026gt; hset htest userpwd asdf (integer) 1 127.0.0.1:6379\u0026gt; hget htest username \u0026#34;hi\u0026#34; 127.0.0.1:6379\u0026gt; hgetall htest 1) \u0026#34;username\u0026#34; 2) \u0026#34;hi\u0026#34; 3) \u0026#34;userpwd\u0026#34; 4) \u0026#34;asdf\u0026#34; hget시에 값이 없다면 (nil)을 반환 1 2 127.0.0.1:6379\u0026gt; hget htest temp (nil) hashkey에 대한 값을 바꿈 1 2 3 4 5 6 127.0.0.1:6379\u0026gt; hget htest userpwd \u0026#34;asdf\u0026#34; 127.0.0.1:6379\u0026gt; hset htest userpwd 1234 (integer) 0 127.0.0.1:6379\u0026gt; hget htest userpwd \u0026#34;1234\u0026#34; Sorted sets value를 set형태로 가지고 있음 Sets과 마찬가지로 중복은 안됨 score와 함께 저장되며 score를 기준으로 정렬됨 list처럼 사용이 될꺼 같으나 정렬된다는 장점이 있는 것 같다 1 2 3 4 5 6 7 127.0.0.1:6379\u0026gt; zadd test_ssets 1 1 (integer) 1 127.0.0.1:6379\u0026gt; zadd test_ssets 2 2 (integer) 1 127.0.0.1:6379\u0026gt; zrange test_ssets 0 -1 1) \u0026#34;1\u0026#34; 2) \u0026#34;2\u0026#34; score를 문자형으로 쓰면 안된다 1 2 127.0.0.1:6379\u0026gt; zadd test_ssets \u0026#34;a\u0026#34; 2 (error) ERR value is not a valid float 중복이 안되면 동일한 value를 넣으면 기존 데이타의 score를 덮어서 데이타 순서가 바뀐다 1 2 3 4 5 127.0.0.1:6379\u0026gt; zadd test_ssets \u0026#34;0\u0026#34; 2 (integer) 0 127.0.0.1:6379\u0026gt; zrange test_ssets 0 -1 1) \u0026#34;2\u0026#34; 2) \u0026#34;1\u0026#34; Bitmaps bit값을 저장해준다 512MB 용량으로 2^32(42억)개의 bit값들을 저장할 수 있다 boolean 옵션값을 저장하는 용도로 사용하면 좋을거 같다 (회원마다 공지 조회여부 등) 1 2 3 4 5 6 7 8 127.0.0.1:6379\u0026gt; setbit test_bits 0 1 (integer) 0 127.0.0.1:6379\u0026gt; getbit test_bits 0 (integer) 1 127.0.0.1:6379\u0026gt; setbit test_bits 0 0 (integer) 1 127.0.0.1:6379\u0026gt; getbit test_bits 0 (integer) 0 ","permalink":"https://kimpaper.github.io/2016/07/27/redis-datatype/","summary":"Redis Data Type 요약 인터넷상에 수많은 좋은 자료가 있음에도 공부 차원에서 정리를 한다\n테스트는 redis-cli를 이용해서 하지만 실제 사용은 언어에 맞는 api library를 사용 할듯\n개요 http://redis.io/topics/data-types-intro\n예제 http://redis.io/topics/data-types\nStrings value에 문자 숫자 등을 저장한다 저장시 별도로 형이 없다 (숫자 문자 구분이 없음) 숫자도 저장가능 하다 그리고 숫자에 incr, incrby, decr, decrby 같은 atomic counter 연산이 가능 incrby, decrby 는 특정 수를 더하거나 뺄때 사용 incrby \u0026quot;test_strings\u0026quot; 10 처럼 사용 1 2 3 4 5 6 7 8 9 10 # redis-cli 127.","title":"redis data type 종류"},{"content":"gradle설치 (for macOS) 1 brew install gradle 원래 수동으로 설치하는 방법이 있으나.. 나는 위와 같이 자동 설치를 좋아한다 대부분 그렇지 않을까~\n수동 설치는 사이트에서 참고하자 https://gradle.org/gradle-download/\npom.xml -\u0026gt; build.gradle로 변환 1 2 # 프로젝트 폴더 (pom.xml이 있는곳) 으로 이동 gradle init --type pom 위와 같이 하면 project name 및 dependencies 등이 gralde용 build script로 변환이 되고 프로젝트가 gradle를 사용가능하도록 설정된다\nintelliJ IDEA에서 기존 maven으로 구성된 프로젝트라면 module을 새로 import해야 한다 (그래야 툴에서 인식이 되는듯 하다)\n꼭 import할때 build.gralde를 선택하자\nbuild.gradle 수정 웹배포용이므로 apply plugin: 'war' 를 추가 한다\nsourceSets를 지정해 빌드 옵션에 맞추어 특정 resource를 로드 하게 설정 한다\n1 2 3 4 sourceSets { main.java.srcDirs=[\u0026#39;src/main/java\u0026#39;] main.resources.srcDirs=[\u0026#39;src/main/resources\u0026#39;, \u0026#39;src/main/resources-\u0026#39; + target] } war파일명 지정과 webContent 패스를 지정한다 1 2 3 4 war { archiveName \u0026#39;api.war\u0026#39; from \u0026#39;webapp\u0026#39; // adds a file-set to the root of the archive } 완성된 build.gradle 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 apply plugin: \u0026#39;java\u0026#39; apply plugin: \u0026#39;war\u0026#39; group = \u0026#39;com.sample\u0026#39; version = \u0026#39;1.0.0\u0026#39; description = \u0026#34;\u0026#34;\u0026#34;api-server\u0026#34;\u0026#34;\u0026#34; sourceCompatibility = 1.7 targetCompatibility = 1.7 repositories { mavenCentral() } dependencies { compile(group: \u0026#39;org.springframework\u0026#39;, name: \u0026#39;spring-context\u0026#39;, version:\u0026#39;4.2.1.RELEASE\u0026#39;) { exclude(module: \u0026#39;commons-logging\u0026#39;) } compile group: \u0026#39;org.springframework\u0026#39;, name: \u0026#39;spring-webmvc\u0026#39;, version:\u0026#39;4.2.1.RELEASE\u0026#39; compile group: \u0026#39;org.springframework\u0026#39;, name: \u0026#39;spring-jdbc\u0026#39;, version:\u0026#39;4.2.1.RELEASE\u0026#39; compile group: \u0026#39;org.springframework\u0026#39;, name: \u0026#39;spring-aop\u0026#39;, version:\u0026#39;4.2.1.RELEASE\u0026#39; compile group: \u0026#39;org.springframework.security\u0026#39;, name: \u0026#39;spring-security-core\u0026#39;, version:\u0026#39;3.2.5.RELEASE\u0026#39; compile group: \u0026#39;org.springframework.data\u0026#39;, name: \u0026#39;spring-data-jpa\u0026#39;, version:\u0026#39;1.9.0.RELEASE\u0026#39; compile group: \u0026#39;org.springframework.amqp\u0026#39;, name: \u0026#39;spring-rabbit\u0026#39;, version:\u0026#39;1.4.1.RELEASE\u0026#39; compile group: \u0026#39;commons-fileupload\u0026#39;, name: \u0026#39;commons-fileupload\u0026#39;, version:\u0026#39;1.2\u0026#39; compile group: \u0026#39;commons-httpclient\u0026#39;, name: \u0026#39;commons-httpclient\u0026#39;, version:\u0026#39;3.0.1\u0026#39; compile group: \u0026#39;commons-dbcp\u0026#39;, name: \u0026#39;commons-dbcp\u0026#39;, version:\u0026#39;1.4\u0026#39; compile group: \u0026#39;commons-lang\u0026#39;, name: \u0026#39;commons-lang\u0026#39;, version:\u0026#39;2.6\u0026#39; compile group: \u0026#39;commons-io\u0026#39;, name: \u0026#39;commons-io\u0026#39;, version:\u0026#39;2.4\u0026#39; compile group: \u0026#39;commons-codec\u0026#39;, name: \u0026#39;commons-codec\u0026#39;, version:\u0026#39;1.10\u0026#39; compile group: \u0026#39;commons-net\u0026#39;, name: \u0026#39;commons-net\u0026#39;, version:\u0026#39;3.3\u0026#39; compile group: \u0026#39;ch.qos.logback\u0026#39;, name: \u0026#39;logback-classic\u0026#39;, version:\u0026#39;1.0.13\u0026#39; compile group: \u0026#39;org.slf4j\u0026#39;, name: \u0026#39;slf4j-api\u0026#39;, version:\u0026#39;1.7.5\u0026#39; compile group: \u0026#39;com.google.code.gson\u0026#39;, name: \u0026#39;gson\u0026#39;, version:\u0026#39;2.2.2\u0026#39; compile group: \u0026#39;mysql\u0026#39;, name: \u0026#39;mysql-connector-java\u0026#39;, version:\u0026#39;5.1.5\u0026#39; compile group: \u0026#39;org.hibernate\u0026#39;, name: \u0026#39;hibernate-entitymanager\u0026#39;, version:\u0026#39;4.3.8.Final\u0026#39; compile group: \u0026#39;com.sun.scn\u0026#39;, name: \u0026#39;sysnet-registration\u0026#39;, version:\u0026#39;1.0.1\u0026#39; testCompile group: \u0026#39;org.springframework\u0026#39;, name: \u0026#39;spring-test\u0026#39;, version:\u0026#39;4.2.1.RELEASE\u0026#39; testCompile group: \u0026#39;junit\u0026#39;, name: \u0026#39;junit\u0026#39;, version:\u0026#39;4.11\u0026#39; providedCompile group: \u0026#39;javax.servlet\u0026#39;, name: \u0026#39;javax.servlet-api\u0026#39;, version:\u0026#39;3.0.1\u0026#39; } sourceSets { main.java.srcDirs=[\u0026#39;src/main/java\u0026#39;] main.resources.srcDirs=[\u0026#39;src/main/resources\u0026#39;, \u0026#39;src/main/resources-\u0026#39; + target] } war { archiveName \u0026#39;api.war\u0026#39; from \u0026#39;webapp\u0026#39; // adds a file-set to the root of the archive } 빌드 빌드시에 Script Parameters를 함께 넣어야 한다 빌드 결과물은 build/libs/api.war 로 확인 할 수 있다\n개발시 개발서버에 바로 배포를 하기 위한 구성 추가 하기! 아래 cargo plugin을 통하여 가능하다 https://github.com/bmuschko/gradle-cargo-plugin\nbuild.gradle에 아래 추가 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 buildscript { repositories { jcenter() } dependencies { classpath \u0026#39;com.bmuschko:gradle-cargo-plugin:2.2.3\u0026#39; } } apply plugin: \u0026#39;com.bmuschko.cargo\u0026#39; ... 중략... ... cargoRedeployRemote { dependsOn war } cargoDeployRemote { dependsOn war } cargo { containerId = \u0026#39;tomcat7x\u0026#39; port = 8083 deployable { context = \u0026#39;api\u0026#39; } remote { hostname = \u0026#39;172.1.20.22\u0026#39; username = \u0026#39;tomcat\u0026#39; password = \u0026#39;password\u0026#39; } } 터미널창에서 실행 1 gradle -Ptarget=dev cargoRedeployRemote ","permalink":"https://kimpaper.github.io/2016/07/14/gradle/","summary":"gradle설치 (for macOS) 1 brew install gradle 원래 수동으로 설치하는 방법이 있으나.. 나는 위와 같이 자동 설치를 좋아한다 대부분 그렇지 않을까~\n수동 설치는 사이트에서 참고하자 https://gradle.org/gradle-download/\npom.xml -\u0026gt; build.gradle로 변환 1 2 # 프로젝트 폴더 (pom.xml이 있는곳) 으로 이동 gradle init --type pom 위와 같이 하면 project name 및 dependencies 등이 gralde용 build script로 변환이 되고 프로젝트가 gradle를 사용가능하도록 설정된다\nintelliJ IDEA에서 기존 maven으로 구성된 프로젝트라면 module을 새로 import해야 한다 (그래야 툴에서 인식이 되는듯 하다)","title":"maven에서 gradle로 변환..."},{"content":"예전에 flume로 에러 로그들을 모으고 있었는데 fluentd로 갈아타려고 한다. 사실 모으는 목적이 아니라 모니터링이 목적\n설치 아래 사이트에 나오는 command만 실행해주면 chkconfig 등록까지 다 해준다. 참고 공식 사이트\nhttp://docs.fluentd.org/articles/install-by-rpm#step-0-before-installation\n구성은 flume와 비슷한것 같다\nclient -\u0026gt; server 구성으로 해놓고 client에서 수집된 로그를 server로 전달.\n아래 커맨드 실행 1 curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh 서비스 구동 1 service td-agent start 당연히 service td-agent stop 가 중지다\n설정 /etc/td-agent/td-agent.conf 파일이 설정 파일이다\n1 vi /etc/td-agent/td-agent.conf simple하게 각 서비스들에 error.log들만 모아서 로그 서버에 파일로 기록 하도록 해보자.\n우선 내가 구성하려고 하는 설정에 필요한 항목은 아래와 같다. \u0026lt;source /\u0026gt;: 데이타 수집 경로, 또는 원격서버로부터 수신 받는다 \u0026lt;match /\u0026gt;: 수집된 로그들을 처리할 액션을 지정 (다른 서버로 전송을 하거나 로컬에 파일로 저장)\n다른 설정값들은 아래 링크에서 확인 해보자 (많다..) http://docs.fluentd.org/articles/config-file#2-ldquomatchrdquo-tell-fluentd-what-to-do\n로그 수집 td-agent.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;source\u0026gt; @type tail path /logs/error.log tag xx.devwas.error format multiline format_firstline /\\[[^\\s]+\\] .*/ format1 /\\[(?\u0026lt;level\u0026gt;[^\\s]+)\\] (?\u0026lt;message\u0026gt;.*)/ \u0026lt;/source\u0026gt; \u0026lt;match xx.*.*\u0026gt; @type forward send_timeout 60s recover_wait 10s heartbeat_interval 1s phi_threshold 16 hard_timeout 60s \u0026lt;server\u0026gt; name logserver host log-server port 24224 weight 60 \u0026lt;/server\u0026gt; \u0026lt;/match\u0026gt; 로그 저장 td-agent.conf 1 2 3 4 5 6 7 8 9 \u0026lt;source\u0026gt; @type forward port 24224 \u0026lt;/source\u0026gt; \u0026lt;match xx.**\u0026gt; @type file path /logs/td/error \u0026lt;/match\u0026gt; 시작시 아래 오류가 나오면 저장 path에 td-agent의 권한을 주자\n1 Starting td-agent: 2016-06-22 14:13:53 +0900 [error]: fluent/supervisor.rb:359:rescue in main_process: config error file=\u0026#34;/etc/td-agent/td-agent.conf\u0026#34; error=\u0026#34;out_file: `/logs/td/~~~` is not writable\u0026#34; 1 chown td-agent td 아래 폴더에 error.시간 으로 저장되는걸 확인 할 수 있다\n1 2 3 4 5 6 [root@logserver td]# ls -al 합계 224 drwxr-xr-x. 2 td-agent root 4096 2016-06-22 15:02 . drwxr-xr-x. 4 root root 4096 2016-06-22 15:16 .. -rw-r--r--. 1 td-agent td-agent 220529 2016-06-22 15:38 error.20160622.b535d7aec407e9135 [root@logserver td]# 그런데 json형태로 저장되고 있다 아무래도 그냥 육안으로 확인은 불편할꺼 같다\n아니면 plugin이 많으니 찾아보자.\n","permalink":"https://kimpaper.github.io/posts/opensource/2016-06-21-fluentd/","summary":"예전에 flume로 에러 로그들을 모으고 있었는데 fluentd로 갈아타려고 한다. 사실 모으는 목적이 아니라 모니터링이 목적\n설치 아래 사이트에 나오는 command만 실행해주면 chkconfig 등록까지 다 해준다. 참고 공식 사이트\nhttp://docs.fluentd.org/articles/install-by-rpm#step-0-before-installation\n구성은 flume와 비슷한것 같다\nclient -\u0026gt; server 구성으로 해놓고 client에서 수집된 로그를 server로 전달.\n아래 커맨드 실행 1 curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent2.sh | sh 서비스 구동 1 service td-agent start 당연히 service td-agent stop 가 중지다\n설정 /etc/td-agent/td-agent.conf 파일이 설정 파일이다\n1 vi /etc/td-agent/td-agent.","title":"fluentd로 로그를 모으기"},{"content":"app에서 데이타 통신을하는 api서버가 있다\n각 인터페이스별 평균 응답시간을 아파치 로그를 활용하여 구해봤다\n서버는 apache+tomcat, spring으로 구현한 서버이다\nhadoop과 spark, python 설정은\nPython and Spark로 로그 파일 분석 (with hadoop) 을 참고 하자\n1. 아파치 TransferLog 로그파일에 응답 시간 남기기 우선 분석하기 전에 아파치 로그에 응답 시간을 추가로 기록하도록 하자\n/etc/httpd/conf.d/ssl.conf 경로에서 아래를 편집했다.\n물론. 설정 파일이 있는 경로와 이름은 서버마다 틀릴 수 있다\n1 2 3 4 5 6 \u0026lt;VirtualHost _default_:443\u0026gt; ... CustomLog logs/ssl_access_log \\ \u0026#34;%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x \\\u0026#34;%r\\\u0026#34; %b %D\u0026#34; ... \u0026lt;/VirtualHost\u0026gt; 기존 TransferLog에 남기지 않고 CustomLog를 하나 더 추가 했다.\n맨 뒤에 %D를 붙이면 응답시간이 마이크로초 단위로 찍히게 된다 더욱 자세한 내용은 아래 링크를 참고 한다\nhttps://httpd.apache.org/docs/2.2/ko/mod/mod_log_config.html\n그래서 로그가 아래와 같이 쌓이는걸 확인 할 수 있다 맨 마지막 스페이스 이후에 숫자가 응답시간이다\n1 2 3 4 [08/Jun/2016:13:37:11 +0900] xx.xx.xx.xx TLSv1 ECDHE-RSA-AES128-SHA \u0026#34;POST /interface/if1 HTTP/1.1\u0026#34; 571 23687 [08/Jun/2016:13:37:14 +0900] xx.xx.xx.xx TLSv1 ECDHE-RSA-AES128-SHA \u0026#34;POST /interface/if2 HTTP/1.1\u0026#34; 711 17120 [08/Jun/2016:13:38:22 +0900] xx.xx.xx.xx TLSv1 ECDHE-RSA-AES128-SHA \u0026#34;POST /interface/if3 HTTP/1.1\u0026#34; 571 36293 [08/Jun/2016:13:38:26 +0900] xx.xx.xx.xx TLSv1 ECDHE-RSA-AES128-SHA \u0026#34;POST /interface/if4 HTTP/1.1\u0026#34; 93 15992 2. python코드 작성 (apachelog.py) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #-*-coding: utf-8 -*- import re import pymysql from pyspark.context import SparkContext pat = re.compile(\u0026#34;/interface/(\\w+)\u0026#34;) def mapLine(line): m = pat.search(line) if m is None: name = \u0026#34;other\u0026#34; else: name = m.group(1) microtime = line[line.rfind(\u0026#34; \u0026#34;):] # 마이크로초이므로 백만을 나눠준다 val = {} val[\u0026#34;avg\u0026#34;] = int(microtime) / 1000 val[\u0026#34;min\u0026#34;] = int(microtime) / 1000 val[\u0026#34;max\u0026#34;] = int(microtime) / 1000 val[\u0026#34;used\u0026#34;] = 1 return (name, val) def reduceLine(a, b): val = {} val[\u0026#34;avg\u0026#34;] = (a[\u0026#34;avg\u0026#34;] + b[\u0026#34;avg\u0026#34;]) / 2 val[\u0026#34;max\u0026#34;] = max(a[\u0026#34;max\u0026#34;], b[\u0026#34;max\u0026#34;]) val[\u0026#34;min\u0026#34;] = min(a[\u0026#34;min\u0026#34;], b[\u0026#34;min\u0026#34;]) val[\u0026#34;used\u0026#34;] = a[\u0026#34;used\u0026#34;] + b[\u0026#34;used\u0026#34;] return val sc = SparkContext(appName=\u0026#34;apache_log\u0026#34;) t = sc.textFile(\u0026#34;/input2/*\u0026#34;) t = t.map(mapLine) t = t.reduceByKey(reduceLine) l = t.collect() l.sort() print(\u0026#34;name\\tavg\\tmax\\tmin\\tcalls\u0026#34;) for data in l: # name, avg, max, min, used print(\u0026#34;%s\\t%d\\t%d\\t%d\\t%d\u0026#34; % (data[0], data[1][\u0026#34;avg\u0026#34;], data[1][\u0026#34;max\u0026#34;], data[1][\u0026#34;min\u0026#34;], data[1][\u0026#34;used\u0026#34;])) print(\u0026#34;완료\u0026#34;) 실행은 아래처럼 해야 한다\n1 $SPARK_HOME/bin/spark-submit --master local[4] apachelog.py ","permalink":"https://kimpaper.github.io/2016/06/08/apachelog/","summary":"app에서 데이타 통신을하는 api서버가 있다\n각 인터페이스별 평균 응답시간을 아파치 로그를 활용하여 구해봤다\n서버는 apache+tomcat, spring으로 구현한 서버이다\nhadoop과 spark, python 설정은\nPython and Spark로 로그 파일 분석 (with hadoop) 을 참고 하자\n1. 아파치 TransferLog 로그파일에 응답 시간 남기기 우선 분석하기 전에 아파치 로그에 응답 시간을 추가로 기록하도록 하자\n/etc/httpd/conf.d/ssl.conf 경로에서 아래를 편집했다.\n물론. 설정 파일이 있는 경로와 이름은 서버마다 틀릴 수 있다\n1 2 3 4 5 6 \u0026lt;VirtualHost _default_:443\u0026gt; .","title":"restful api 서버에서 평균 응답시간, 호출횟수, Min, Max 구하기"},{"content":"Spark를 이용한 파일 분석 spark도 잘 모르고 hadoop도 잘 모르는 상태에서 진행해서 틀린 부분이 있을 것이다.\n참고로 OSX에서 진행된 작업이다.\n설정 1. Hadoop를 설치 하고 실행한다 2. hdfs상에 파일을 올린다. 1 2 cd /logs hdfs dfs -put test.log /input/ 아래와 같이 파일 브라우징이 가능하다 아래에서 올라간 파일을 확인! http://localhost:50070/explorer.html#/input\n3. spark의 python 커맨드 테스트.. $SPARK_HOME/bin/pyspark 하둡을 켜고 pyspark를 실행하면 아래와 같이 나온다\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Python 2.7.10 (default, Oct 23 2015, 19:19:21) [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwin Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. 16/05/30 16:12:16 INFO spark.SparkContext: Running Spark version 1.6.1 2016-05-30 16:12:17.194 java[5956:1259148] Unable to load realm info from SCDynamicStore ... 중략 .... 16/05/30 16:12:19 INFO storage.BlockManagerMasterEndpoint: Registering block manager localhost:50791 with 511.0 MB RAM, BlockManagerId(driver, localhost, 50791) 16/05/30 16:12:19 INFO storage.BlockManagerMaster: Registered BlockManager Welcome to ____ __ / __/__ ___ _____/ /__ _\\ \\/ _ \\/ _ `/ __/ \u0026#39;_/ /__ / .__/\\_,_/_/ /_/\\_\\ version 1.6.1 /_/ Using Python version 2.7.10 (default, Oct 23 2015 19:19:21) SparkContext available as sc, HiveContext available as sqlContext. \u0026gt;\u0026gt;\u0026gt; 4. python 환경 잡기 (spark-submit 환경임) 1 2 # 환경변수 설정을 위해 아래 파일을 연다 (물론 OSX 기준) vi ~/.bash_profile .bash_profile파일에 아래와 같이 추가 한다\n1 2 3 4 5 export SPARK_HOME=/Users/paper/dev/tool/spark export PYTHONPATH=$SPARK_HOME/python/:$PYTHONPATH export IPYTHON=1 export PYSPARK_PYTHON=python3.5 export PYSPARK_DRIVER_PYTHON=ipython 혹시 ipython이 없다면 아래 명령어로 설치 한다\n1 pip install ipython 1 2 3 4 5 # 적용 source ~/.bash_profile # py4j는 pyspark가 사용하는 모듈이니 설치 해야 함 pip3.5 install py4j 5. voicelog.py파일 작성후 간단한 테스트 1 2 3 4 5 6 7 #-*-coding: utf-8 -*- from pyspark.context import SparkContext sc = SparkContext() t = sc.textFile(\u0026#34;/input/test.log\u0026#34;) print(t.count()) 1 $SPARK_HOME/bin/spark-submit --master local[4] voicelog.py 아래와 같이 결과를 볼 수 있다\n1 2 3 4 5 6 7 8 9 10 16/05/30 17:52:58 INFO spark.SparkContext: Running Spark version 1.6.1 2016-05-30 17:52:58.646 java[7629:1534234] Unable to load realm info from SCDynamicStore 16/05/30 17:52:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 16/05/30 17:52:58 INFO spark.SecurityManager: Changing view acls to: paper ... 중략 ... 16/05/30 17:53:03 INFO scheduler.DAGScheduler: Job 0 finished: count at /Users/paper/dev/git/createXlsFromDb/search_voice_log/voicelog.py:8, took 1.541395 s 145410 16/05/30 17:53:03 INFO spark.SparkContext: Invoking stop() from shutdown hook ... 중략 ... 16/05/30 17:53:03 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down. 툴설정 (IntelliJ IDEA) 우선 파일이 연결되는걸 확인했으니 .. intellij에서 연동하는걸 해보자. 코드에 pyspark 보이게 하기\n프로젝트 환경설정에서 SDKs 에 아래와 같이 라이브러리를 추가해 준다 실행 스크립트 연결\n$SPARK_HOME/bin/spark-submit --master local[4] voicelog.py 를 실행하도록 구성해준다\n구현 voicelog.py 파일 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #-*-coding: utf-8 -*- from pyspark.context import SparkContext def mapLine(line): # lineblock를 불러와서 필요한 부분만 가공하여 tuple형태로 반환한다 str = line[1][:line[1].find(\u0026#34;.pcm\u0026#34;)] str2 = str.split(\u0026#34;/\u0026#34;) sent_cd = str2[1][str2[1].find(\u0026#34;_\u0026#34;)+1:] data = str2[0] + \u0026#34;/\u0026#34; + sent_cd return (data, 1) def printLine(line): print(line) sc = SparkContext(appName=\u0026#34;voicelog\u0026#34;) # /input/ 경로에 있는 모든 파일을 가져와서 분석을 실시한다 # sc.textFile로 하려고 했으나.분석 대상이 multi line이어서 아래를 이용한다 t = sc.newAPIHadoopFile( \u0026#39;/input/\u0026#39;, \u0026#39;org.apache.hadoop.mapreduce.lib.input.TextInputFormat\u0026#39;, \u0026#39;org.apache.hadoop.io.LongWritable\u0026#39;, \u0026#39;org.apache.hadoop.io.Text\u0026#39;, conf={\u0026#39;textinputformat.record.delimiter\u0026#39;: \u0026#39;/text/\u0026#39;} ) # block중에 record가 포함되지 않고 -11문자열을 포함하는 block만 RDD로 뽑는다 l = t.filter(lambda data: \u0026#34;/record/\u0026#34; not in data[1] and \u0026#34;-11\u0026#34; in data[1]) # reduceByKey를 한 이유는 몇번이나 발생했는지를 나타낸다 - 사실 중복제거를 하려고 했는데. groupByKey를 사용해도 괜찮다 l = l.map(mapLine).reduceByKey(lambda a, b: a + b).collect() # 결과 파일에 쓴다 f = open(\u0026#34;result.log\u0026#34;, \u0026#34;w\u0026#34;) for s in l: f.write(\u0026#34;%s, %d\\r\\n\u0026#34; % (s[0], s[1])) f.close() print(\u0026#34;완료\u0026#34;) 실행 방법 1 $SPARK_HOME/bin/spark-submit --master local[4] voicelog.py 참고로 spark-submit --help를 쳐보면 많은 옵션을 확인 할 수 있다\n스파크 서버에 연결하여 실행 스파크를 실행해서 클러스터 구성후에 연동하는 법은 아래 처럼 스파크를 따로 실행해놓고 python코드에서 스파크 주소를 쓰면 되는것 같다\n안해봤다\n1 $SPARK_HOME/sbin/start-all.sh 위에 MasterUI를 자세히 보면 URL: spark://로 시작 하는 부분을 확인 할 수 있다.\n1 SparkContext(\u0026#34;spark://.....\u0026#34;, \u0026#34;voicelog\u0026#34;) 예전에는 단순히 오류 추적에만 사용했던 로그였기에 기간이 지나면 자동삭제하게 해놨었는데.. 앞으로는 로그를 잘 모아놔야겠다\n일단 로그 쓸때 가치 있는 데이타를 좀 포함시켜보자\n","permalink":"https://kimpaper.github.io/posts/opensource/2016-05-30-spark-hadoop/","summary":"Spark를 이용한 파일 분석 spark도 잘 모르고 hadoop도 잘 모르는 상태에서 진행해서 틀린 부분이 있을 것이다.\n참고로 OSX에서 진행된 작업이다.\n설정 1. Hadoop를 설치 하고 실행한다 2. hdfs상에 파일을 올린다. 1 2 cd /logs hdfs dfs -put test.log /input/ 아래와 같이 파일 브라우징이 가능하다 아래에서 올라간 파일을 확인! http://localhost:50070/explorer.html#/input\n3. spark의 python 커맨드 테스트.. $SPARK_HOME/bin/pyspark 하둡을 켜고 pyspark를 실행하면 아래와 같이 나온다\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Python 2.","title":"Python and Spark로 로그 파일 분석 (with hadoop)"},{"content":"AWS ec2 서버에는 password로 ssh접근이 안되도록 되어 있다. 아래 파일을 수정하여 접근이 되도록 해보자.\ncentos 6.5에서 작업한 것이다\n1 2 # 루트계정에 패스워드 지정 passwd root 1 2 3 4 5 6 7 8 sudo vi /etc/ssh/sshd_config # 아래 두개 옵션을 yes로 하고 저장후 닫기 PermitRootLogin yes PasswordAuthentication yes # sshd 재시작 service sshd restart ","permalink":"https://kimpaper.github.io/2016/04/08/amazon-ec2-root-pwd/","summary":"AWS ec2 서버에는 password로 ssh접근이 안되도록 되어 있다. 아래 파일을 수정하여 접근이 되도록 해보자.\ncentos 6.5에서 작업한 것이다\n1 2 # 루트계정에 패스워드 지정 passwd root 1 2 3 4 5 6 7 8 sudo vi /etc/ssh/sshd_config # 아래 두개 옵션을 yes로 하고 저장후 닫기 PermitRootLogin yes PasswordAuthentication yes # sshd 재시작 service sshd restart ","title":"AWS EC2서버에 패스워드로 로그인 하기"},{"content":"요즘엔 git을 많이 이용하는데 항상 rebase와 merge에 대해서 헷갈리곤 했다.\n잘 모를때 rebase로 하다가 소스를 날려먹은 후로는.. merge만 써왔다\n최근에 몇군데 찾아봤는데 rebase 는 branch의 base를 재배치 한다는 의미라고 한다. gitflow를 쓰면서 feature를 새로 만들어서 작업을 하다 그동안 쌓인 develop를 rebase를 해봤는데. feature에서 작업하던 도중 쌓인 develop의 commit들이 local feature밑으로 들어가지는걸 확인했다.\n히스토리가 꼬이지 않아 좋지만 한가지 문제는 feature를 서버로 push한 상태라면.. feature브런치가 두개가 생겨버린다 물론 로컬이 최신이므로 remote/origin을 feature를 삭제하고 신규로 push하면 해결되는것 같다.\n그림을 그려서 설명하면 참 좋겠지만.. 그림을 못그린다.\nrebase시에 컴플릿은 local feature에서 commit한걸 기준으로 한번씩 단계적으로 해결을 resolve를 해나가는데.\n이 과정에서 원하는 결과가 제대로 안나올수 있다. (파일 하나의 resolve 작업을 여러번 해야 하는데..)\nrebase 를 이용하려면 되도록 주기를 짧게 가져가는것이 좋을것같다.\n","permalink":"https://kimpaper.github.io/posts/etc/2016-03-24-git-rebase-merge/","summary":"요즘엔 git을 많이 이용하는데 항상 rebase와 merge에 대해서 헷갈리곤 했다.\n잘 모를때 rebase로 하다가 소스를 날려먹은 후로는.. merge만 써왔다\n최근에 몇군데 찾아봤는데 rebase 는 branch의 base를 재배치 한다는 의미라고 한다. gitflow를 쓰면서 feature를 새로 만들어서 작업을 하다 그동안 쌓인 develop를 rebase를 해봤는데. feature에서 작업하던 도중 쌓인 develop의 commit들이 local feature밑으로 들어가지는걸 확인했다.\n히스토리가 꼬이지 않아 좋지만 한가지 문제는 feature를 서버로 push한 상태라면.. feature브런치가 두개가 생겨버린다 물론 로컬이 최신이므로 remote/origin을 feature를 삭제하고 신규로 push하면 해결되는것 같다.","title":"git에서 rebase와 merge"},{"content":"아래와 같이 복구 대상 저장소를 지정한다 (현재 checkout이 develop인 경우)\n1 git reset --hard remotes/origin/develop 저장소를 지정하지 않으면 현재 checkout된 remote를 기준으로 revert하는것 같다\n1 git reset --hard ","permalink":"https://kimpaper.github.io/posts/etc/2016-02-25-git-revert-local-commit/","summary":"아래와 같이 복구 대상 저장소를 지정한다 (현재 checkout이 develop인 경우)\n1 git reset --hard remotes/origin/develop 저장소를 지정하지 않으면 현재 checkout된 remote를 기준으로 revert하는것 같다\n1 git reset --hard ","title":"git local commit revert 시키기"},{"content":"요즘 파이썬 공부중인데 연습겸 10초마다 webserver가 죽었는지 체크하는 간단한 프로그램을 만들어 봤다.\n아래코드에는 아래 나열된 사항들에 대한 코딩이 적용되어 있다\nhttp request thread(timer 대응) logging사용법 try-except 예외처리 raise throw json parsing 및 데이타 읽기 방법 string 처리 ServerCheck.py 파일 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 import threading import urllib.request import json import time import logging logger = logging.getLogger(\u0026#34;myLogger\u0026#34;) # 이런 로그 파일 셋팅 def config_logger(): formatter = logging.Formatter(\u0026#34;[%(levelname)s] %(asctime)s - %(message)s\u0026#34;) file_handler = logging.FileHandler(\u0026#34;/logs/py/log.log\u0026#34;) stream_handler = logging.StreamHandler() file_handler.setFormatter(formatter) stream_handler.setFormatter(formatter) logger.addHandler(file_handler) logger.addHandler(stream_handler) logger.setLevel(logging.DEBUG) def call_error(name, e): logger.error(\u0026#34;%s에서 \u0026#39;%s\u0026#39;가 발생했습니다\u0026#34; % (name, e)) def check_server(name, url): try: check_server_private(url) logger.info(\u0026#34;서버 체크 완료 name=%s\u0026#34; % name) except Exception as e: call_error(name, e) def check_server_private(url): req = urllib.request.urlopen(url) try: if req.getcode() != 200: raise RuntimeError(\u0026#34;서버 오류\u0026#34;) data = req.read() json_object = json.loads(str(data, \u0026#34;utf-8\u0026#34;), \u0026#34;utf-8\u0026#34;) if json_object[\u0026#34;result_code\u0026#34;] != \u0026#34;0000\u0026#34;: raise RuntimeError(\u0026#34;서버 응답 오류\u0026#34;) finally: req.close() def check_all(): check_server(\u0026#34;server1\u0026#34;, \u0026#34;http://server1/checkjson\u0026#34;) check_server(\u0026#34;server2\u0026#34;, \u0026#34;http://server2/checkjson\u0026#34;) def run_thread(): while True: check_all() time.sleep(10) config_logger() th = threading.Thread(target=run_thread) th.start() logger.info(\u0026#34;모니터링 시작 합니다\u0026#34;) 실행 방법 1 python ServerCheck.py 근데 타이머를 저런식으로 해도 될런지 모르겠네 \u0026hellip;\n","permalink":"https://kimpaper.github.io/posts/python/2016-02-17-python-http-request/","summary":"요즘 파이썬 공부중인데 연습겸 10초마다 webserver가 죽었는지 체크하는 간단한 프로그램을 만들어 봤다.\n아래코드에는 아래 나열된 사항들에 대한 코딩이 적용되어 있다\nhttp request thread(timer 대응) logging사용법 try-except 예외처리 raise throw json parsing 및 데이타 읽기 방법 string 처리 ServerCheck.py 파일 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 import threading import urllib.","title":"Python으로 간단한 webserver 체크"},{"content":"centos 6에 3.5.1 버전을 설치 하는 command line 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 yum install zlib-devel -y yum install openssl openssl-devel -y wget https://www.python.org/ftp/python/3.5.1/Python-3.5.1.tar.xz xz -d Python-3.5.1.tar.xz # 혹시 xz가 없다면 yum install xz 로 설치 하라. tar -xvf Python-3.5.1.tar cd Python-3.5.1 ./configure --prefix=/usr/local --enable-shared LDFLAGS=\u0026#34;-Wl,-rpath /usr/local/lib\u0026#34; make \u0026amp;\u0026amp; make altinstall # pip설치 curl -k -O https://bootstrap.pypa.io/get-pip.py python3.5 get-pip.py 간단한 프로그램에는 Python이 좋은듯 java는 프로젝트 구성하기도 귀찮고\u0026hellip;\n","permalink":"https://kimpaper.github.io/posts/python/2016-02-12-install-python3/","summary":"centos 6에 3.5.1 버전을 설치 하는 command line 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 yum install zlib-devel -y yum install openssl openssl-devel -y wget https://www.python.org/ftp/python/3.5.1/Python-3.5.1.tar.xz xz -d Python-3.5.1.tar.xz # 혹시 xz가 없다면 yum install xz 로 설치 하라. tar -xvf Python-3.5.1.tar cd Python-3.5.1 ./configure --prefix=/usr/local --enable-shared LDFLAGS=\u0026#34;-Wl,-rpath /usr/local/lib\u0026#34; make \u0026amp;\u0026amp; make altinstall # pip설치 curl -k -O https://bootstrap.pypa.io/get-pip.py python3.5 get-pip.py 간단한 프로그램에는 Python이 좋은듯 java는 프로젝트 구성하기도 귀찮고\u0026hellip;","title":"CentOS 6에서 Python3 설치 하기"},{"content":"맥용 Unity로 개발할때 보통 MonoDevelopr를 이용하여 코딩 한다 그런데 한글을 지원안해서. 아주 불편했는데.\nMS에서 얼마전에 공개한 mac용 VisualStudio Code에서 유니티를 지원한다고 해서 한번 설정해봤다.\n설치 우선 VS code를 설치 한다 https://code.visualstudio.com/\n커맨드+P를 누르고. ext install Omnisharp 추가 기능으로 설치 한다 안해도 되는거 같기도\u0026hellip;\n맥의 터미널 상에 brew install mono 로 mono를 설치한다 오래걸린다\n이후로는 아래 사이트를 따라 하면 된다 https://code.visualstudio.com/docs/runtimes/unity\ngit clone https://github.com/dotBunny/VSCode.git를 내려받고 Plugins\\Editor\\dotBunny 폴더를 자신의 유니티 프로젝트 내부에 넣는다\n그리고 Unity Preferences에 가면 VSCode 라는 탭이 제일 아래 생긴다 모두 체크하고 Write Workspace Settings 버튼을 누른다\n이제. cs파일을 더블클릭하면 프로젝트가 VS Code로 열릴 것이다.\n디버깅 VSCode상에서 원하는 부분에 브레이크 포인트를 건다 . (거는 방법은.. 에디터에서 맨 왼쪽을 클릭 하면 빨간 점이 나온다.) F5를 누르면 디버깅 상태로 들어간다 그리고 유니티를 실행한다 ","permalink":"https://kimpaper.github.io/posts/etc/2015-12-18-unity-with-visualstudio-code/","summary":"맥용 Unity로 개발할때 보통 MonoDevelopr를 이용하여 코딩 한다 그런데 한글을 지원안해서. 아주 불편했는데.\nMS에서 얼마전에 공개한 mac용 VisualStudio Code에서 유니티를 지원한다고 해서 한번 설정해봤다.\n설치 우선 VS code를 설치 한다 https://code.visualstudio.com/\n커맨드+P를 누르고. ext install Omnisharp 추가 기능으로 설치 한다 안해도 되는거 같기도\u0026hellip;\n맥의 터미널 상에 brew install mono 로 mono를 설치한다 오래걸린다\n이후로는 아래 사이트를 따라 하면 된다 https://code.visualstudio.com/docs/runtimes/unity\ngit clone https://github.com/dotBunny/VSCode.git를 내려받고 Plugins\\Editor\\dotBunny 폴더를 자신의 유니티 프로젝트 내부에 넣는다","title":"맥에서 Unity3D 기본 에디터로 VisualStudio Code 사용하기"},{"content":"쿼리 튜닝할때 아래를 실행하고 하면 cache 안된 결과를 볼 수 있다.\n1 RESET QUERY CACHE; ","permalink":"https://kimpaper.github.io/posts/etc/2015-12-15-mysql-cache-reset/","summary":"쿼리 튜닝할때 아래를 실행하고 하면 cache 안된 결과를 볼 수 있다.\n1 RESET QUERY CACHE; ","title":"Mariadb Query test할때 cache 안먹게 하기"},{"content":"Test.java에서 처럼 EntityManager를 이용하여 orm.xml에 정의한 NamedQuery를 바로 실행 할 수 있다..\nrepository를 이용하여 호출하면 getResultList로만 실행되는 것 같다. update 반영된 Row수를 알기 위해 아래와 같이 호출 했다.\nTest.java 1 2 3 4 5 6 @PersistenceContext private EntityManager em; public void test() { int cnt = em.createNamedQuery(\u0026#34;Order.clearOrder\u0026#34;).executeUpdate(); logger.info(\u0026#34;Order.clearOrder updated={}\u0026#34;, cnt); } @PersistenceContext private EntityManager em; 에서..\n@PersistenceContext @Autowired 둘다 작동 하는것 같다. 차이는 아직 잘 모르겠다.\nMETA-INF/orm.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;entity-mappings xmlns=\u0026#34;http://java.sun.com/xml/ns/persistence/orm\u0026#34; version=\u0026#34;2.0\u0026#34;\u0026gt; \u0026lt;named-native-query name=\u0026#34;Order.clearOrder\u0026#34;\u0026gt; \u0026lt;query\u0026gt; update tb_order set order_name=null , order_date=null , order_no=null , order_state=\u0026#39;S00\u0026#39; \u0026lt;/query\u0026gt; \u0026lt;/named-native-query\u0026gt; \u0026lt;/entity-mappings\u0026gt; ","permalink":"https://kimpaper.github.io/posts/spring/2015-11-13-spring-jpa-createnamedquery/","summary":"Test.java에서 처럼 EntityManager를 이용하여 orm.xml에 정의한 NamedQuery를 바로 실행 할 수 있다..\nrepository를 이용하여 호출하면 getResultList로만 실행되는 것 같다. update 반영된 Row수를 알기 위해 아래와 같이 호출 했다.\nTest.java 1 2 3 4 5 6 @PersistenceContext private EntityManager em; public void test() { int cnt = em.createNamedQuery(\u0026#34;Order.clearOrder\u0026#34;).executeUpdate(); logger.info(\u0026#34;Order.clearOrder updated={}\u0026#34;, cnt); } @PersistenceContext private EntityManager em; 에서..\n@PersistenceContext @Autowired 둘다 작동 하는것 같다. 차이는 아직 잘 모르겠다.\nMETA-INF/orm.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;?","title":"spring jpa namedQuery 직접 호출하기"},{"content":"pom.xml 에 아래 추가. 1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.data\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 버전을 잘 맞춰야 한다. 안그러면 몇몇 class가 없어서 오류가 발생해요.\ncontext-redis.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:p=\u0026#34;http://www.springframework.org/schema/p\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;jedisConnFactory\u0026#34; class=\u0026#34;org.springframework.data.redis.connection.jedis.JedisConnectionFactory\u0026#34; p:usePool=\u0026#34;true\u0026#34; p:hostName=\u0026#34;172.xxx.xxx.xxx\u0026#34; p:port=\u0026#34;6379\u0026#34; /\u0026gt; \u0026lt;!-- redis template definition --\u0026gt; \u0026lt;bean id=\u0026#34;redisTemplate\u0026#34; class=\u0026#34;org.springframework.data.redis.core.RedisTemplate\u0026#34; p:connectionFactory-ref=\u0026#34;jedisConnFactory\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 6379가 redis기본 포트이다. 설치시 변경 가능하다.\nRedisTest.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( { \u0026#34;classpath:spring/application-context.xml\u0026#34; } ) public class RedisTest { private static final Logger logger = LoggerFactory.getLogger(RedisTest.class); @Autowired RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate; @Resource(name=\u0026#34;redisTemplate\u0026#34;) private ValueOperations\u0026lt;String, ResultMap\u0026gt; valueOps; @Test public void testTp4110() throws Exception { // redisTemplate.delete(\u0026#34;1\u0026#34;); ResultMap res = valueOps.get(\u0026#34;1\u0026#34;); if(res == null) { logger.info(\u0026#34;create.. cache..\u0026#34;); // create.. // 10분 캐시 valueOps.set(\u0026#34;1\u0026#34;, ResultMap.create(), 10, TimeUnit.MINUTES); res = valueOps.get(\u0026#34;1\u0026#34;); } logger.info(\u0026#34;redis-test={}\u0026#34;, res); res = valueOps.get(\u0026#34;2\u0026#34;); logger.info(\u0026#34;redis-test={}\u0026#34;, res); } } 실행 결과 1 2 3 4 5 ... [INFO ] 17:30:28.990 [main] - create.. cache.. [INFO ] 17:30:29.190 [main] - redis-test={result_code=0000, result_message=success} [INFO ] 17:30:29.288 [main] - redis-test=null ... ","permalink":"https://kimpaper.github.io/posts/spring/2015-11-11-spring-redis/","summary":"pom.xml 에 아래 추가. 1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.data\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 버전을 잘 맞춰야 한다. 안그러면 몇몇 class가 없어서 오류가 발생해요.\ncontext-redis.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:p=\u0026#34;http://www.springframework.org/schema/p\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;jedisConnFactory\u0026#34; class=\u0026#34;org.springframework.data.redis.connection.jedis.JedisConnectionFactory\u0026#34; p:usePool=\u0026#34;true\u0026#34; p:hostName=\u0026#34;172.xxx.xxx.xxx\u0026#34; p:port=\u0026#34;6379\u0026#34; /\u0026gt; \u0026lt;!","title":"spring redis 연동 "},{"content":"flume에 logback로 로그 파일 쓰기 flume에 logback 설치 방법 (http://logback.qos.ch/download.html) 에서 logback 다운로드 한다 . (현재 v1.1.3) 압축을 풀고. logback-classic-1.1.3.jar, logback-core-1.1.3.jar 를 $FLUME_HOME/lib에 복사해 넣는다. 기존 log4j는 ./lib/slf4j-log4j12-1.6.1.jar를 ./lib/slf4j-log4j12-1.6.1.jar.back로 이름을 바꾼다. log4j를 지우는 것은 선택사항이다 (놔두면 둘다 기록 한다) logback.xml 파일을 수정해서 $FLUME_HOME/conf/logback.xml에 넣는다. logback.xml 샘플 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- Appenders --\u0026gt; \u0026lt;appender name=\u0026#34;console\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;[%-5level] %d{HH:mm:ss.SSS} [%thread] %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;daily\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;prudent\u0026gt;false\u0026lt;/prudent\u0026gt; \u0026lt;file\u0026gt;./logs/flume1.log\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;./logs/old/flume1.%d{yyyy-MM-dd}.%i.log\u0026lt;/fileNamePattern\u0026gt; \u0026lt;timeBasedFileNamingAndTriggeringPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\u0026#34;\u0026gt; \u0026lt;maxFileSize\u0026gt;100mb\u0026lt;/maxFileSize\u0026gt; \u0026lt;/timeBasedFileNamingAndTriggeringPolicy\u0026gt; \u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;[%-5level] %d{HH:mm:ss.SSS} %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;event\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;prudent\u0026gt;false\u0026lt;/prudent\u0026gt; \u0026lt;file\u0026gt;./logs/collect.log\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;./logs/old/collect.%d{yyyy-MM-dd}.%i.log\u0026lt;/fileNamePattern\u0026gt; \u0026lt;timeBasedFileNamingAndTriggeringPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\u0026#34;\u0026gt; \u0026lt;maxFileSize\u0026gt;100mb\u0026lt;/maxFileSize\u0026gt; \u0026lt;/timeBasedFileNamingAndTriggeringPolicy\u0026gt; \u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;logger name=\u0026#34;kimpaper\u0026#34; level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;event\u0026#34; /\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;!-- 3rdparty Loggers --\u0026gt; \u0026lt;logger name=\u0026#34;org.apache.flume.lifecycle\u0026#34; level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;logger name=\u0026#34;org.jboss\u0026#34; level=\u0026#34;warn\u0026#34;\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;logger name=\u0026#34;org.mortbay\u0026#34; level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;logger name=\u0026#34;org.apache.avro.ipc.NettyTransceiver\u0026#34; level=\u0026#34;warn\u0026#34;\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;logger name=\u0026#34;org.apache.hadoop\u0026#34; level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;logger name=\u0026#34;org.apache.hadoop.hive\u0026#34; level=\u0026#34;error\u0026#34;\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;!-- Root Logger --\u0026gt; \u0026lt;root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;console\u0026#34; /\u0026gt; \u0026lt;appender-ref ref=\u0026#34;daily\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; logback에 event 기록 하도록 설정 마스터 서버에서 로그를 모아 저장하는 sink로 file_roll를 이용하려고 했으나 단점이 있다.\n파일명 지정 못함 로그파일이 계속 쌓임 위 단점은 생각보다 큰 단점이어서 간단한 sink 프로젝트를 만들었다.\nhttps://github.com/kimpaper/flume-slj4j-sink 설치 방법은 위 사이트에서 참고\nconf/flume-agent1.conf 1 2 3 4 5 ... agent1.sinks.k1.type = kimpaper.flume.sink.Slj4jSink agent1.sinks.k1.logLevel = info agent1.sinks.k1.channel = c1 ... sink는 위와 같이 적용 한다.\n이제 각 서버에서 오는 log들이 collect.log 파일에 병합되어 쌓이는걸 확인 할 수 있다.\n","permalink":"https://kimpaper.github.io/posts/centos/2015-10-30-flume-logback-sink/","summary":"flume에 logback로 로그 파일 쓰기 flume에 logback 설치 방법 (http://logback.qos.ch/download.html) 에서 logback 다운로드 한다 . (현재 v1.1.3) 압축을 풀고. logback-classic-1.1.3.jar, logback-core-1.1.3.jar 를 $FLUME_HOME/lib에 복사해 넣는다. 기존 log4j는 ./lib/slf4j-log4j12-1.6.1.jar를 ./lib/slf4j-log4j12-1.6.1.jar.back로 이름을 바꾼다. log4j를 지우는 것은 선택사항이다 (놔두면 둘다 기록 한다) logback.xml 파일을 수정해서 $FLUME_HOME/conf/logback.xml에 넣는다. logback.xml 샘플 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 \u0026lt;?","title":"Flume의 기본 로그를 log4j에서 logback으로 변경"},{"content":"logback을 이용하는 경우 오늘이 지나거나 용량이 100메가를 넘어가면 파일이 분리된다.\nlogback.xml 에 아래 appender 추가 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;appender name=\u0026#34;debug\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;DEBUG\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;prudent\u0026gt;false\u0026lt;/prudent\u0026gt; \u0026lt;file\u0026gt;/logs/debug.log\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;/logs/old/debug.%d{yyyy-MM-dd}.%i.log\u0026lt;/fileNamePattern\u0026gt; \u0026lt;timeBasedFileNamingAndTriggeringPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\u0026#34;\u0026gt; \u0026lt;maxFileSize\u0026gt;100mb\u0026lt;/maxFileSize\u0026gt; \u0026lt;/timeBasedFileNamingAndTriggeringPolicy\u0026gt; \u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;[%-5level] %d{HH:mm:ss.SSS} %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;maxFileSize /\u0026gt; 는 분할할 용량이다 (kb, gb도 된다) \u0026lt;maxHistory /\u0026gt; 30일 지난 로그는 오래된 순서대로 지워준다. ","permalink":"https://kimpaper.github.io/2015/10/30/logback-config/","summary":"logback을 이용하는 경우 오늘이 지나거나 용량이 100메가를 넘어가면 파일이 분리된다.\nlogback.xml 에 아래 appender 추가 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;appender name=\u0026#34;debug\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;filter class=\u0026#34;ch.qos.logback.classic.filter.ThresholdFilter\u0026#34;\u0026gt; \u0026lt;level\u0026gt;DEBUG\u0026lt;/level\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;prudent\u0026gt;false\u0026lt;/prudent\u0026gt; \u0026lt;file\u0026gt;/logs/debug.log\u0026lt;/file\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;/logs/old/debug.%d{yyyy-MM-dd}.%i.log\u0026lt;/fileNamePattern\u0026gt; \u0026lt;timeBasedFileNamingAndTriggeringPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\u0026#34;\u0026gt; \u0026lt;maxFileSize\u0026gt;100mb\u0026lt;/maxFileSize\u0026gt; \u0026lt;/timeBasedFileNamingAndTriggeringPolicy\u0026gt; \u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;[%-5level] %d{HH:mm:ss.SSS} %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;maxFileSize /\u0026gt; 는 분할할 용량이다 (kb, gb도 된다) \u0026lt;maxHistory /\u0026gt; 30일 지난 로그는 오래된 순서대로 지워준다.","title":"logback에서 시간 + 용량 기준으로 로그파일 분할하기"},{"content":"Flume 란? 여러대(여러서비스..)에 기록되는 로그파일들을 실시간으로 한곳으로 모아주는 서비스 설치 http://flume.apache.org/download.html 에서 다운로드 한다. 적절한 곳에 압축을 풀어 준다 ~/dev/tool/flume JAVA_HOME이 지정되 있지 않으면. ~/.bash_profile 을 열어 환경 변수를 설정해 준다. 1 export JAVA_HOME = /usr (자바 경로.) 설치 및 테스트는 mac에서 했지만. centos에서도 잘되리라 믿는다.\n기본 flume.conf 파일 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # The configuration file needs to define the sources, # the channels and the sinks. # Sources, channels and sinks are defined per agent, # in this case called \u0026#39;agent\u0026#39; agent.sources = seqGenSrc agent.channels = memoryChannel agent.sinks = loggerSink # For each one of the sources, the type is defined agent.sources.seqGenSrc.type = seq # The channel can be defined as follows. agent.sources.seqGenSrc.channels = memoryChannel # Each sink\u0026#39;s type must be defined agent.sinks.loggerSink.type = logger #Specify the channel the sink should use agent.sinks.loggerSink.channel = memoryChannel # Each channel\u0026#39;s type is defined. agent.channels.memoryChannel.type = memory # Other config values specific to each type of channel(sink or source) # can be defined as well # In this case, it specifies the capacity of the memory channel agent.channels.memoryChannel.capacity = 100 참고) https://flume.apache.org/FlumeUserGuide.html 설정파일은 sources, channels, sinks 로 나눠져 있다.\nsources: 읽어오는 대상 (원격 서버에서 전달받기도 한다.) channels: 아마\u0026hellip; sinks로 저장하기 위한 버퍼? 같은 역할인것 같음 솔찍히 모름 sinks: 저장할 대상 또는 전달할 대상? 아래 그림을 보면 살짝 이해가 된다. (아래 그림에는 저장 대상이 하둡인데.. 나는 하둡을 이용하진 않을 것이다.)\n그림출처) https://flume.apache.org/FlumeUserGuide.html\n다양한 sources 형식이 있으나 나는 로그 파일로부터 tail명령을 이용하여 수집한다.\nagent1은 agent2에서 수집된 로그를 전달 받는다 agent2는 수집된 로그를 agent1으로 전송 한다. 저장하는 서버 agent1 (flume/conf/flume-agent1.conf) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 agent1.sources = r1 agent1.channels = c1 agent1.sinks = k1 # 원격의 서버들로부터 데이타를 수신한다 (port는 4545) agent1.sources.r1.type = avro agent1.sources.r1.bind = 0.0.0.0 agent1.sources.r1.port = 4545 agent1.sources.r1.channels = c1 agent1.channels.c1.type = memory agent1.channels.c1.capacity = 10000 agent1.channels.c1.transactionCapacity = 1000 # /logs/flume에 저장한다 agent1.sinks.k1.type = file_roll agent1.sinks.k1.sink.directory = /logs/flume # 하루(24 hour) 단위로 파일.. rolling. agent1.sinks.k1.sink.rollInterval = 86400 agent1.sinks.k1.channel = c1 저장서버로 로그를 전송 하는 서버 (여러대로 늘어난다) agent2 (flume/conf/flume-agent2.conf) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 agent2.sources = r1 r2 agent2.channels = c1 agent2.sinks = k1 # 파일로 부터 로그를 읽어 온다. agent2.sources.r1.type = exec agent2.sources.r1.command = tail -F /logs/debug.log agent2.sources.r1.channels = c1 agent2.sources.r2.type = exec agent2.sources.r2.command = tail -F /logs/info.log agent2.sources.r2.channels = c1 agent2.channels.c1.type = memory agent2.channels.c1.capacity = 10000 agent2.channels.c1.transactionCapacity = 1000 # 원격의 서버로 전달 한다. (난 로컬에서 테스트 하니까 127.0.0.1:4545) agent2.sinks.k1.type = avro agent2.sinks.k1.channel = c1 agent2.sinks.k1.hostname = 127.0.0.1 agent2.sinks.k1.port = 4545 위에 sources를 두개 지정할 수 있다 (파일이 다른 경우)\n서비스 실행 두가지 설정을 한 서비스를 각각 실행 하자.\n1 2 ./bin/flume-ng agent -c ./conf -f ./conf/flume-agent1.conf -n agent1 ./bin/flume-ng agent -c ./conf -f ./conf/flume-agent2.conf -n agent2 -c, --conf 설정폴더 -f, --conf-file 설정파일 -n, --name 에이전트 이름 agent1에서 sinks를 file_roll로 하니 아래와 같이 file list들이 쌓인다. sink.rollInterval 속성을 이용해서 interval은 조정 가능 하다. (아래는 30초 기준이다.)\n1 2 3 4 5 6 7 8 9 10 gimjonghuiui-MacBook-Pro:flume paper$ ls -l total 24 -rw-r--r-- 1 paper wheel 0 10 29 15:40 1446100807777-1 -rw-r--r-- 1 paper wheel 95 10 29 15:40 1446100818312-1 -rw-r--r-- 1 paper wheel 519 10 29 15:41 1446100818312-2 -rw-r--r-- 1 paper wheel 0 10 29 15:41 1446100818312-3 -rw-r--r-- 1 paper wheel 378 10 29 15:42 1446100818312-4 -rw-r--r-- 1 paper wheel 0 10 29 15:42 1446100818312-5 -rw-r--r-- 1 paper wheel 0 10 29 15:42 1446100818312-6 -rw-r--r-- 1 paper wheel 0 10 29 15:43 1446100818312-7 ","permalink":"https://kimpaper.github.io/posts/centos/2015-10-29-flume-setting-sample/","summary":"Flume 란? 여러대(여러서비스..)에 기록되는 로그파일들을 실시간으로 한곳으로 모아주는 서비스 설치 http://flume.apache.org/download.html 에서 다운로드 한다. 적절한 곳에 압축을 풀어 준다 ~/dev/tool/flume JAVA_HOME이 지정되 있지 않으면. ~/.bash_profile 을 열어 환경 변수를 설정해 준다. 1 export JAVA_HOME = /usr (자바 경로.) 설치 및 테스트는 mac에서 했지만. centos에서도 잘되리라 믿는다.\n기본 flume.conf 파일 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # The configuration file needs to define the sources, # the channels and the sinks.","title":"Flume 설치 및 테스트 (mac)"},{"content":"sitemesh를 설정을 해보겠습니다.\npom.xml 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;opensymphony\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sitemesh\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; WEB-INF/web.xml 에 아래 추가. 1 2 3 4 5 6 7 8 \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;sitemesh\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;com.opensymphony.module.sitemesh.filter.PageFilter\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;sitemesh\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; WEB-INF/sitemesh.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;sitemesh\u0026gt; \u0026lt;property name=\u0026#34;decorators-file\u0026#34; value=\u0026#34;/WEB-INF/decorators.xml\u0026#34; /\u0026gt; \u0026lt;excludes file=\u0026#34;${decorators-file}\u0026#34; /\u0026gt; \u0026lt;page-parsers\u0026gt; \u0026lt;parser content-type=\u0026#34;text/html\u0026#34; class=\u0026#34;com.opensymphony.module.sitemesh.parser.HTMLPageParser\u0026#34; /\u0026gt; \u0026lt;parser content-type=\u0026#34;text/html;charset=UTF-8\u0026#34; class=\u0026#34;com.opensymphony.module.sitemesh.parser.HTMLPageParser\u0026#34; /\u0026gt; \u0026lt;/page-parsers\u0026gt; \u0026lt;decorator-mappers\u0026gt; \u0026lt;mapper class=\u0026#34;com.opensymphony.module.sitemesh.mapper.PrintableDecoratorMapper\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;decorator\u0026#34; value=\u0026#34;printable\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;parameter.name\u0026#34; value=\u0026#34;printable\u0026#34; /\u0026gt; \u0026lt;param name=\u0026#34;parameter.value\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/mapper\u0026gt; \u0026lt;mapper class=\u0026#34;com.opensymphony.module.sitemesh.mapper.PageDecoratorMapper\u0026#34; \u0026gt; \u0026lt;param name=\u0026#34;property\u0026#34; value=\u0026#34;meta.decorator\u0026#34; /\u0026gt; \u0026lt;/mapper\u0026gt; \u0026lt;mapper class=\u0026#34;com.opensymphony.module.sitemesh.mapper.ConfigDecoratorMapper\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;config\u0026#34; value=\u0026#34;${decorators-file}\u0026#34; /\u0026gt; \u0026lt;/mapper\u0026gt; \u0026lt;/decorator-mappers\u0026gt; \u0026lt;/sitemesh\u0026gt; sitemesh.xml파일은 수정할 부분이 거의 없습니다 (decorators.xml파일 경로)\nWEB-INF/decorators.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;decorators defaultdir=\u0026#34;/decorators\u0026#34;\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;pattern\u0026gt;/*.json\u0026lt;/pattern\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;decorator name=\u0026#34;top\u0026#34; page=\u0026#34;/views/layout/top.jsp\u0026#34; /\u0026gt; \u0026lt;decorator name=\u0026#34;left\u0026#34; page=\u0026#34;/views/layout/left.jsp\u0026#34; /\u0026gt; \u0026lt;decorator name=\u0026#34;layout2\u0026#34; page=\u0026#34;/views/layout/layout2.jsp\u0026#34;\u0026gt; \u0026lt;pattern\u0026gt;/login\u0026lt;/pattern\u0026gt; \u0026lt;pattern\u0026gt;/login_error\u0026lt;/pattern\u0026gt; \u0026lt;/decorator\u0026gt; \u0026lt;decorator name=\u0026#34;layout\u0026#34; page=\u0026#34;/views/layout/layout.jsp\u0026#34;\u0026gt; \u0026lt;pattern\u0026gt;/*\u0026lt;/pattern\u0026gt; \u0026lt;/decorator\u0026gt; \u0026lt;/decorators\u0026gt; 셋팅은 위와 같이 xml만 넣어주면 완료됩니다.\n\u0026lt;excludes\u0026gt;에는 decorator를 적용하지 않을 url패턴을 입력합니다. \u0026lt;decorator\u0026gt;실제 적용될 jsp 레이아웃이나 템플릿입니다. name, page 로 구성되며 name은 \u0026lt;page:applyDecorator name=\u0026quot;top\u0026quot; /\u0026gt; 처럼 다른 decorator에 적용될 수 있습니다. \u0026lt;pattern\u0026gt;/login\u0026lt;/pattern\u0026gt;은 decorator를 적용할 Url을 지정합니다. 사용법 기본 레이아웃인 layout.jsp 파일 입니다.\n/views/layout/layout.jsp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u0026lt;%@ page language=\u0026#34;java\u0026#34; contentType=\u0026#34;text/html; charset=UTF-8\u0026#34; pageEncoding=\u0026#34;UTF-8\u0026#34;%\u0026gt; \u0026lt;%@ taglib prefix=\u0026#34;decorator\u0026#34; uri=\u0026#34;http://www.opensymphony.com/sitemesh/decorator\u0026#34;%\u0026gt; \u0026lt;%@ taglib prefix=\u0026#34;page\u0026#34; uri=\u0026#34;http://www.opensymphony.com/sitemesh/page\u0026#34; %\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;sample\u0026lt;/title\u0026gt; \u0026lt;decorator:head/\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;wrapper\u0026#34;\u0026gt; \u0026lt;header class=\u0026#34;main-header\u0026#34;\u0026gt; \u0026lt;page:applyDecorator name=\u0026#34;top\u0026#34; /\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;!-- Left side column. contains the logo and sidebar --\u0026gt; \u0026lt;aside class=\u0026#34;main-sidebar\u0026#34;\u0026gt; \u0026lt;page:applyDecorator name=\u0026#34;left\u0026#34; /\u0026gt; \u0026lt;/aside\u0026gt; \u0026lt;!-- Content Wrapper. Contains page content --\u0026gt; \u0026lt;div class=\u0026#34;content-wrapper\u0026#34;\u0026gt; \u0026lt;decorator:body /\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;!-- /.content-wrapper --\u0026gt; \u0026lt;footer class=\u0026#34;main-footer\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;pull-right hidden-xs\u0026#34;\u0026gt; \u0026lt;b\u0026gt;Version\u0026lt;/b\u0026gt; 0.0.1 \u0026lt;/div\u0026gt; \u0026lt;strong\u0026gt;Copyright \u0026amp;copy; 2015 sample \u0026lt;/strong\u0026gt; All rights reserved. \u0026lt;/footer\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 제가 사용하는 layout.jsp를 그대로 올린건 아니고 간단히 요약을 했습니다. (오류가 있을수도..)\n\u0026lt;decorator:head /\u0026gt; 적용되는 대상 페이지에서 \u0026lt;head\u0026gt; 의 내용을 가져다 붙여 줍니다. \u0026lt;page:applyDecorator name=\u0026quot;top\u0026quot; /\u0026gt; top의 decorator를 가져와 붙여 줍니다. (include 라고 생각하시면 이해가 빨라요!) \u0026lt;page:applyDecorator name=\u0026quot;left\u0026quot; /\u0026gt; left의 decorator를 가져와 붙여 줍니다. \u0026lt;decorator:body /\u0026gt; 적용되는 대상 페이지에서 \u0026lt;body\u0026gt; 의 내용을 가져와 붙입니다. 이제 실제로 MVC에서 사용하는 jsp파일입니다.\n/views/appInfo/list.jsp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 \u0026lt;%@ page language=\u0026#34;java\u0026#34; contentType=\u0026#34;text/html; charset=UTF-8\u0026#34; pageEncoding=\u0026#34;UTF-8\u0026#34;%\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- page script --\u0026gt; \u0026lt;script\u0026gt; .... \u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- Content Header (Page header) --\u0026gt; \u0026lt;section class=\u0026#34;content-header\u0026#34;\u0026gt; \u0026lt;h1\u0026gt; 데이타 관리 \u0026lt;small\u0026gt;버전관리\u0026lt;/small\u0026gt; \u0026lt;/h1\u0026gt; \u0026lt;ol class=\u0026#34;breadcrumb\u0026#34;\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;\u0026lt;i class=\u0026#34;fa fa-dashboard\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;데이타관리\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;active\u0026#34;\u0026gt;버전관리\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;!-- Main content --\u0026gt; \u0026lt;section class=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;row\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;col-xs-12\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;box\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;box-header\u0026#34;\u0026gt; \u0026lt;h3 class=\u0026#34;box-title\u0026#34;\u0026gt;버전 목록\u0026lt;/h3\u0026gt; \u0026lt;a href=\u0026#34;create\u0026#34;\u0026gt;\u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;btn btn-primary btn-lg pull-right\u0026#34;\u0026gt;신규 추가\u0026lt;/button\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;!-- /.box-header --\u0026gt; \u0026lt;div class=\u0026#34;box-body\u0026#34;\u0026gt; \u0026lt;table id=\u0026#34;list\u0026#34; class=\u0026#34;table table-bordered table-hover\u0026#34;\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;!-- /.box-body --\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;!-- /.box --\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;!-- /.col --\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;!-- /.row --\u0026gt; \u0026lt;/section\u0026gt;\u0026lt;!-- /.content --\u0026gt; \u0026lt;/body\u0026gt; list.jsp와 같이 원하는 jsp에 \u0026lt;head\u0026gt; \u0026lt;body\u0026gt;를 구성하면 layout.jsp의 형식으로 출력되게 됩니다.\n","permalink":"https://kimpaper.github.io/2015/10/28/spring-sitemesh-setting/","summary":"sitemesh를 설정을 해보겠습니다.\npom.xml 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;opensymphony\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sitemesh\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; WEB-INF/web.xml 에 아래 추가. 1 2 3 4 5 6 7 8 \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;sitemesh\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;com.opensymphony.module.sitemesh.filter.PageFilter\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;sitemesh\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; WEB-INF/sitemesh.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;sitemesh\u0026gt; \u0026lt;property name=\u0026#34;decorators-file\u0026#34; value=\u0026#34;/WEB-INF/decorators.xml\u0026#34; /\u0026gt; \u0026lt;excludes file=\u0026#34;${decorators-file}\u0026#34; /\u0026gt; \u0026lt;page-parsers\u0026gt; \u0026lt;parser content-type=\u0026#34;text/html\u0026#34; class=\u0026#34;com.","title":"spring + sitemesh 웹사이트 구축"},{"content":"jpa에서는 저장시 repository.save 함수를 이용하여 저장합니다\nMember class처럼 @OneToMany나 @ManyToOne 필드들을 함께 저장 할 수 있습니다.\nMember.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Entity @Table(name = \u0026#34;tb_member\u0026#34;) public class Member { @Id @GeneratedValue(strategy = GenerationType.AUTO) @Column(name = \u0026#34;member_seq\u0026#34;) public Integer memberSeq; @Column public String nickname; @Expose @OneToMany( targetEntity = MemberInter.class , cascade = CascadeType.ALL , fetch = FetchType.EAGER , mappedBy = \u0026#34;memberSeq\u0026#34;) public List\u0026lt;MemberInter\u0026gt; memberInterList; } MemberInter.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Entity @Table(name=\u0026#34;tb_member_inter\u0026#34;) @IdClass(value = MemberInterPk.class) public class MemberInter { @Id @Column(name = \u0026#34;member_seq\u0026#34;) public Integer memberSeq; @Id @Column(name = \u0026#34;inter_seq\u0026#34;) public Integer interSeq; @ManyToOne( targetEntity = Inter.class ,cascade = CascadeType.ALL ,fetch = FetchType.LAZY ,optional = false ) @JoinColumn(name = \u0026#34;inter_seq\u0026#34;, referencedColumnName = \u0026#34;inter_seq\u0026#34; , insertable = false, updatable = false) public Inter inter; } @JoinColumn에 insertable, updateable을 추가 하여 false 했습니다\nTest method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Test public void testSave() throws Exception{ logger.info(\u0026#34;------------ jpa test starting.... ------------------------\u0026#34;); Member data = memberRepository.findByNickname(\u0026#34;111\u0026#34;); logger.info(\u0026#34;data={}\u0026#34;, gson.toJson(data)); data.nickname = \u0026#34;222\u0026#34;; MemberInter memberInter = new MemberInter(); memberInter.interSeq = 28; memberInter.memberSeq = data.memberSeq; MemberInter memberInter2 = new MemberInter(); memberInter2.interSeq = 29; memberInter2.memberSeq = data.memberSeq; data.memberInterList.add(memberInter); data.memberInterList.add(memberInter2); // 실제 저장. (member클래스를 저장. 한다) memberRepository.save(data); logger.info(\u0026#34;------------ jpa test ended.... ------------------------\u0026#34;); } 위 test method를 실행하면 아래와 같이 sql가 실행됩니다 1 2 3 4 5 ... ... Hibernate: insert into tb_member_inter (inter_seq, member_seq) values (?, ?) Hibernate: insert into tb_member_inter (inter_seq, member_seq) values (?, ?) Hibernate: update tb_member set nickname=? where member_seq=? 로그에서 insert into가 두번 호출 되고 update도 한번 실행되는것을 확인 할 수 있습니다.\n","permalink":"https://kimpaper.github.io/2015/10/21/jpa-save/","summary":"jpa에서는 저장시 repository.save 함수를 이용하여 저장합니다\nMember class처럼 @OneToMany나 @ManyToOne 필드들을 함께 저장 할 수 있습니다.\nMember.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Entity @Table(name = \u0026#34;tb_member\u0026#34;) public class Member { @Id @GeneratedValue(strategy = GenerationType.AUTO) @Column(name = \u0026#34;member_seq\u0026#34;) public Integer memberSeq; @Column public String nickname; @Expose @OneToMany( targetEntity = MemberInter.class , cascade = CascadeType.ALL , fetch = FetchType.","title":"spring jpa 저장"},{"content":"c++ 로 된 dll을 c#에서 호출할때 예제입니다.\n먼저 c++ 코드들을 간단히 짰습니다. test.h 1 extern \u0026#34;C\u0026#34; __declspec(dllexport) int test(LPCTSTR szFileName); test.cpp 1 2 3 int test(LPCTSTR szFileName) { return 0; } 다음은 c#쪽 코드들입니다 1 2 3 4 5 6 7 8 9 [DllImport(\u0026#34;sampleLib.dll\u0026#34;, CallingConvention = CallingConvention.Cdecl)] private static extern int test( [MarshalAs(UnmanagedType.LPWStr)] string szFileName); private void button2_Click(object sender, EventArgs e) { string szFileName = @\u0026#34;c:\\filename.txt\u0026#34;; int result = test(ticketName); Debug.WriteLine(\u0026#34;test=\u0026#34; + result); } CallingConvention = CallingConvention.Cdecl와 [MarshalAs(UnmanagedType.LPWStr)] 가 중요합니다.\n반대로 c++에서 string을 받는건 IntPtr로 받아 아래와 같이 하면 됩니다. 1 2 3 4 IntPtr ptr = test(\u0026#34;111111\u0026#34;); string data = Marshal.PtrToStringAnsi(ptr); // 꼭 해제 한다 Marshal.FreeHGlobal(data); ","permalink":"https://kimpaper.github.io/2015/10/15/csharp-lpcstr-parameter-call/","summary":"c++ 로 된 dll을 c#에서 호출할때 예제입니다.\n먼저 c++ 코드들을 간단히 짰습니다. test.h 1 extern \u0026#34;C\u0026#34; __declspec(dllexport) int test(LPCTSTR szFileName); test.cpp 1 2 3 int test(LPCTSTR szFileName) { return 0; } 다음은 c#쪽 코드들입니다 1 2 3 4 5 6 7 8 9 [DllImport(\u0026#34;sampleLib.dll\u0026#34;, CallingConvention = CallingConvention.Cdecl)] private static extern int test( [MarshalAs(UnmanagedType.LPWStr)] string szFileName); private void button2_Click(object sender, EventArgs e) { string szFileName = @\u0026#34;c:\\filename.txt\u0026#34;; int result = test(ticketName); Debug.","title":"c# 에서 c++(dll)로 LPCTSTR parameter 넘겨 호출 하기"},{"content":"예전에 했던 대로 System.Drawing 을 써서 하려고 했는데.. wpf에 이런 기능이 있었네..\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // uiPage.ren public void DoPageToPng(string fileName) { RenderTargetBitmap rtb = new RenderTargetBitmap((int)uiPage.ActualWidth, (int)uiPage.ActualHeight, 96, 96, PixelFormats.Pbgra32); rtb.Render(uiPage); PngBitmapEncoder png2 = new PngBitmapEncoder(); png2.Frames.Add(BitmapFrame.Create(rtb)); using (MemoryStream stream = new MemoryStream()) { png2.Save(stream); using (System.Drawing.Image image = System.Drawing.Image.FromStream(stream)) { image.Save(fileName); } } } ","permalink":"https://kimpaper.github.io/posts/dotnet/2015-10-16-wpf-control-save-to-png/","summary":"예전에 했던 대로 System.Drawing 을 써서 하려고 했는데.. wpf에 이런 기능이 있었네..\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // uiPage.ren public void DoPageToPng(string fileName) { RenderTargetBitmap rtb = new RenderTargetBitmap((int)uiPage.ActualWidth, (int)uiPage.ActualHeight, 96, 96, PixelFormats.Pbgra32); rtb.Render(uiPage); PngBitmapEncoder png2 = new PngBitmapEncoder(); png2.Frames.Add(BitmapFrame.Create(rtb)); using (MemoryStream stream = new MemoryStream()) { png2.Save(stream); using (System.Drawing.Image image = System.Drawing.Image.FromStream(stream)) { image.Save(fileName); } } } ","title":"WPF(c#)에서 control을 png로 저장"},{"content":"jpa에서.. repository를 이용하여 findAll이나.. findOneBy\u0026hellip;. 시리즈를 써서 데이타를 조회 할수 있지만 아래와 같이 특정 쿼리를 직접 입력하여 이용도 가능합니다.\n/classes/META-INF/orm.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;entity-mappings xmlns=\u0026#34;http://java.sun.com/xml/ns/persistence/orm\u0026#34; version=\u0026#34;2.0\u0026#34;\u0026gt; \u0026lt;named-query name=\u0026#34;Inter.findByAlal2\u0026#34;\u0026gt; \u0026lt;query\u0026gt;select i from Inter i where i.internameko = ?1\u0026lt;/query\u0026gt; \u0026lt;/named-query\u0026gt; \u0026lt;named-native-query name=\u0026#34;Inter.findByAlal\u0026#34; result-class=\u0026#34;sample.jpa.Inter\u0026#34;\u0026gt; \u0026lt;query\u0026gt;select a.inter_seq, a.inter_name_ko, a.inter_name_en from tb_inter a where a.inter_name_ko = ?\u0026lt;/query\u0026gt; \u0026lt;/named-native-query\u0026gt; \u0026lt;/entity-mappings\u0026gt; 또는.. 아래와 같이 Entity 클래스에 선언해도 됩니다\n1 2 3 4 5 6 @Entity @Table(name=\u0026#34;tb_inter\u0026#34;) @NamedQuery(name = \u0026#34;User.findByAlal2\u0026#34;, query = \u0026#34;select i from Inter i where i.internameko = ?1\u0026#34;) public class Inter { .... } (비슷한 속성으로는 @Query도 사용가능하고. 이 속성은 Repository에 사용합니다.)\nnamed-query와 named-native-query의 차이점\nnamed-query는 현재 코드내에 선언한 Entity를 기준으로 쿼리를 날린다. (Inter.java파일 참고) named-native-query는 db에 직접 쿼리를 날린다. (그러므로 result-class를 지정해야 한다.) Inter.java 1 2 3 4 5 6 7 8 9 @Entity @Table(name=\u0026#34;tb_inter\u0026#34;) public class Inter { @Id @Column(name = \u0026#34;inter_seq\u0026#34;) @GeneratedValue(strategy = GenerationType.AUTO) private Integer interseq; @Column(name = \u0026#34;inter_name_ko\u0026#34;) @Expose private String internameko; @Column(name = \u0026#34;inter_name_en\u0026#34;) @Expose private String internameen; } ","permalink":"https://kimpaper.github.io/posts/spring/2015-10-08-spring-jpa-namedquery-namednativequery/","summary":"jpa에서.. repository를 이용하여 findAll이나.. findOneBy\u0026hellip;. 시리즈를 써서 데이타를 조회 할수 있지만 아래와 같이 특정 쿼리를 직접 입력하여 이용도 가능합니다.\n/classes/META-INF/orm.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;entity-mappings xmlns=\u0026#34;http://java.sun.com/xml/ns/persistence/orm\u0026#34; version=\u0026#34;2.0\u0026#34;\u0026gt; \u0026lt;named-query name=\u0026#34;Inter.findByAlal2\u0026#34;\u0026gt; \u0026lt;query\u0026gt;select i from Inter i where i.internameko = ?1\u0026lt;/query\u0026gt; \u0026lt;/named-query\u0026gt; \u0026lt;named-native-query name=\u0026#34;Inter.findByAlal\u0026#34; result-class=\u0026#34;sample.jpa.Inter\u0026#34;\u0026gt; \u0026lt;query\u0026gt;select a.inter_seq, a.inter_name_ko, a.inter_name_en from tb_inter a where a.inter_name_ko = ?\u0026lt;/query\u0026gt; \u0026lt;/named-native-query\u0026gt; \u0026lt;/entity-mappings\u0026gt; 또는.. 아래와 같이 Entity 클래스에 선언해도 됩니다","title":"spring jpa의 @NamedQuery, @NamedNativeQuery 연습"},{"content":"entity 작업에 조회까지.. 테스트 해봤습니다.\n테이블의 관계가 아래와 같을때 상황 1 tb_member -\u0026lt; tb_member_inter \u0026gt;- tb_inter 조회 조건\nMember를 가져오면.. member의 이미지들과\u0026hellip; inter의 목록을 함께 가져오도록 inter의 상세 정보는 tb_inter에 있음 (가져올때 조인해서..) 아래 class들 간략 설명\nMemberInter의 PK가 두개이므로. 위와 같이 클래스를 하나 만들어서 @IdClass를 지정해야 함 @Expose 는 Gson관련하여 화면에 뿌릴 필드를 정하는 옵션입니다. jpa와는 무관합니다. MemberInter.class에서 많이 헷갈렸습니다. (@ManyToOne) @JoinColumn을 추가로.. 써야 합니다. optional을 true로 하면 join시 outer join을 합니다. (false는 inner join) FetchType\nFetchType.EAGER -\u0026gt; 즉시 조회해서 데이타 채움 FetchType.LAZY -\u0026gt; 필요시 DB조회 필드명은 카멜케이스CamelCase를 꼭 써야 한다. 안그럼 나중에 method named query 시에 곤란해진다.\nMember.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Entity @Table(name = \u0026#34;tb_member\u0026#34;) public class Member { @Id @GeneratedValue(strategy = GenerationType.AUTO) private Integer member_seq; @Expose @OneToMany( targetEntity = Image.class , cascade = CascadeType.ALL , fetch = FetchType.EAGER , mappedBy = \u0026#34;member_seq\u0026#34;) private List\u0026lt;image\u0026gt; imageList; @Expose @OneToMany( targetEntity = MemberInter.class , cascade = CascadeType.ALL , fetch = FetchType.EAGER , mappedBy = \u0026#34;member_seq\u0026#34;) private List\u0026lt;Memberinter\u0026gt; memberInterList; } MemberRepository.java 1 2 3 public interface MemberRepository extends JpaRepository\u0026lt;Member, Integer\u0026gt; { } Image.java 1 2 3 4 5 6 7 8 9 10 11 @Entity @Table(name = \u0026#34;tb_image\u0026#34;) public class Image { @Id @GeneratedValue private Integer image_seq; @Column private Integer member_seq; @Column @Expose private String file_name; } Inter.java 1 2 3 4 5 6 7 @Entity @Table(name=\u0026#34;tb_inter\u0026#34;) @Embeddable public class Inter { @Id @GeneratedValue(strategy = GenerationType.AUTO) private Integer inter_seq; @Column @Expose private String inter_name_ko; } MemberInter.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Entity @Table(name=\u0026#34;tb_member_inter\u0026#34;) @IdClass(MemberInterPk.class) public class MemberInter { @Id @Column private Integer member_seq; @Id @Column(insertable = false, updatable = false) private Integer inter_seq; @ManyToOne( targetEntity = Inter.class ,cascade = CascadeType.ALL ,fetch = FetchType.EAGER ,optional = false ) @JoinColumn(name = \u0026#34;inter_seq\u0026#34;) @Expose private Inter inter; } MemberInterPk.java 1 2 3 4 public class MemberInterPk implements Serializable { private Integer member_seq; private Integer inter_seq; } test 코드\u0026hellip;\nTestServiceTest.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration({ \u0026#34;classpath:servlet-context.xml\u0026#34;, \u0026#34;classpath:config/context-datasource.xml\u0026#34; }) public class TestServiceTest { private static final Logger logger = LoggerFactory.getLogger(TestServiceTest.class); @Autowired private Gson gson; @Autowired private MemberRepository memberRepository; @Test public void testGetMemberList() throws Exception { logger.info(\u0026#34;------------ jpa test starting.... ------------------------\u0026#34;); List\u0026amp;lt;member\u0026gt; list = memberRepository.findAll(); logger.info(\u0026#34;memberList={}\u0026#34;, gson.toJson(list)); logger.info(\u0026#34;------------ jpa test ended.... ------------------------\u0026#34;); } } ","permalink":"https://kimpaper.github.io/posts/spring/2015-10-08-spring-jpa/","summary":"entity 작업에 조회까지.. 테스트 해봤습니다.\n테이블의 관계가 아래와 같을때 상황 1 tb_member -\u0026lt; tb_member_inter \u0026gt;- tb_inter 조회 조건\nMember를 가져오면.. member의 이미지들과\u0026hellip; inter의 목록을 함께 가져오도록 inter의 상세 정보는 tb_inter에 있음 (가져올때 조인해서..) 아래 class들 간략 설명\nMemberInter의 PK가 두개이므로. 위와 같이 클래스를 하나 만들어서 @IdClass를 지정해야 함 @Expose 는 Gson관련하여 화면에 뿌릴 필드를 정하는 옵션입니다. jpa와는 무관합니다. MemberInter.class에서 많이 헷갈렸습니다. (@ManyToOne) @JoinColumn을 추가로.. 써야 합니다. optional을 true로 하면 join시 outer join을 합니다.","title":"spring jpa 조회 연습 "},{"content":"거의 대부분 mybatis 를 이용하여 개발을 하는데..\nJPA가 대세라고 해서 가벼운 프로젝트에 연동을 해봤습니다.\n1. 라이브러리 import\u0026hellip;. maven pom.xml 1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.data\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.hibernate\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hibernate-entitymanager\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.8.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. Entity class를 만들어 줍니다. 참고로 SerializedName, Expose는 jpa와 직접 관련은 없습니다.. (개체를 그대로 JsonView 할때 사용)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 import com.google.gson.annotations.Expose; import com.google.gson.annotations.SerializedName; import javax.persistence.*; @Entity @Table(name=\u0026#34;tb_notice\u0026#34;) public class Notice { @Id @GeneratedValue(strategy = GenerationType.AUTO) @Column(name = \u0026#34;notice_id\u0026#34;) @SerializedName(value = \u0026#34;notice_id\u0026#34;) @Expose private Integer noticeId; @Column(name=\u0026#34;title\u0026#34;, nullable = false) @Expose private String title; @Column(name=\u0026#34;content\u0026#34;, nullable = false) @Expose private String content; @Column(name=\u0026#34;reg_date\u0026#34;, nullable = false) @SerializedName(value = \u0026#34;reg_date\u0026#34;) @Expose private String regDate; @Column(name=\u0026#34;del_yn\u0026#34;, nullable = false) @Expose(serialize = false, deserialize = false) private String delYn; public Integer getNoticeId() { return noticeId; } public void setNoticeId(Integer noticeId) { this.noticeId = noticeId; } public String getTitle() { return title; } public void setTitle(String title) { this.title = title; } public String getContent() { return content; } public void setContent(String content) { this.content = content; } public String getRegDate() { return regDate; } public void setRegDate(String regDate) { this.regDate = regDate; } public String getDelYn() { return delYn; } public void setDelYn(String delYn) { this.delYn = delYn; } } 3. repository 를 만들어줍니다. (아무것도 없어도 된다) 1 2 3 public interface NoticeRepository extends JpaRepository\u0026lt;Notice, Integer\u0026gt; { } 4. context-jpa.xml 설정합니다. txManager2인 이유는 기존에 mybatis에 영향을 주지 않기 위해서입니다. , mybatis를 한번에 다 걷어낼 자신이 없\u0026hellip; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:jpa=\u0026#34;http://www.springframework.org/schema/data/jpa\u0026#34; xmlns:tx=\u0026#34;http://www.springframework.org/schema/tx\u0026#34; xmlns:aop=\u0026#34;http://www.springframework.org/schema/aop\u0026#34; xmlns:p=\u0026#34;http://www.springframework.org/schema/util\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.1.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.1.xsd \u0026#34;\u0026gt; \u0026lt;!-- Configure the transaction manager bean --\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.orm.jpa.JpaTransactionManager\u0026#34; id=\u0026#34;txManager2\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;entityManagerFactory\u0026#34; ref=\u0026#34;entityManagerFactory\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;tx:advice id=\u0026#34;txAdvice2\u0026#34; transaction-manager=\u0026#34;txManager2\u0026#34;\u0026gt; \u0026lt;tx:attributes\u0026gt; \u0026lt;tx:method name=\u0026#34;*\u0026#34; rollback-for=\u0026#34;Exception\u0026#34; /\u0026gt; \u0026lt;/tx:attributes\u0026gt; \u0026lt;/tx:advice\u0026gt; \u0026lt;aop:config\u0026gt; \u0026lt;aop:pointcut expression=\u0026#34;execution(* sample..service..*.sr*(..))\u0026#34; id=\u0026#34;requiredTx2\u0026#34; /\u0026gt; \u0026lt;aop:advisor advice-ref=\u0026#34;txAdvice2\u0026#34; pointcut-ref=\u0026#34;requiredTx2\u0026#34; /\u0026gt; \u0026lt;/aop:config\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter\u0026#34; id=\u0026#34;hibernateJpaVendorAdapter\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;showSql\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- Configure the entity manager factory bean --\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean\u0026#34; id=\u0026#34;entityManagerFactory\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;jpaVendorAdapter\u0026#34; ref=\u0026#34;hibernateJpaVendorAdapter\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;packagesToScan\u0026#34; value=\u0026#34;sample.app\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;jpa:repositories base-package=\u0026#34;sample.app\u0026#34; transaction-manager-ref=\u0026#34;txManager2\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 5. 사용 예제 1 2 3 4 5 6 7 8 9 10 11 12 @Service public class NoticeService extends ServiceBase { private static final Logger logger = LoggerFactory.getLogger(NoticeService.class); @Autowired private NoticeRepository noticeRepository; public void srXX(RequestData req, ResponseData res) throws Exception { List\u0026lt;Notice\u0026gt; list = noticeRepository.findAll(); res.put(\u0026#34;notice_list\u0026#34;, list); } } 인터넷상에 자료가 많아서 설정은 어렵지 않았습니다.\n하지만 실제로 사용에 요령이 필요하다고 하네요.. (제대로 이해를 하지 않고 사용하면 성능에도 영향을 준다고 함)\n","permalink":"https://kimpaper.github.io/2015/10/05/spring-jpa-maven/","summary":"거의 대부분 mybatis 를 이용하여 개발을 하는데..\nJPA가 대세라고 해서 가벼운 프로젝트에 연동을 해봤습니다.\n1. 라이브러리 import\u0026hellip;. maven pom.xml 1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.data\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.9.0.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.hibernate\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hibernate-entitymanager\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.8.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. Entity class를 만들어 줍니다. 참고로 SerializedName, Expose는 jpa와 직접 관련은 없습니다.. (개체를 그대로 JsonView 할때 사용)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 import com.","title":"spring jpa 설정 및 테스트 (maven 설정)"},{"content":"컴파일러를 먼저 설치해야 합니다. (설치돼 있다면 패스) 1 yum install gcc gcc-c++ autoconf automake 참고) http://www.redis.io/download\n설치 1 2 3 4 5 6 7 # 다운로드 및 설치 (컴파일) wget http://download.redis.io/releases/redis-3.2.3.tar.gz tar xzf redis-3.2.3.tar.gz cd redis-3.2.3 make \u0026amp;\u0026amp; make install cd utils ./install_server.sh 실행로그 확인 1 tail -f /var/log/redis_6379.log -n 1000 로그에서 Warning 없애기 vi /etc/sysctl.conf 파일에 아래 추가 1 2 vm.overcommit_memory=1 fs.file-max = 1048576 vi /etc/rc.local 파일에 아래 추가 1 2 echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled sysctl -w net.core.somaxconn=65535 vi /etc/security/limits.conf 파일에 아래 추가 1 2 3 4 * soft nofile 65536 * hard nofile 65536 * soft nproc 131072 * hard nproc 131072 ","permalink":"https://kimpaper.github.io/posts/opensource/2015-09-21-redis-304/","summary":"컴파일러를 먼저 설치해야 합니다. (설치돼 있다면 패스) 1 yum install gcc gcc-c++ autoconf automake 참고) http://www.redis.io/download\n설치 1 2 3 4 5 6 7 # 다운로드 및 설치 (컴파일) wget http://download.redis.io/releases/redis-3.2.3.tar.gz tar xzf redis-3.2.3.tar.gz cd redis-3.2.3 make \u0026amp;\u0026amp; make install cd utils ./install_server.sh 실행로그 확인 1 tail -f /var/log/redis_6379.log -n 1000 로그에서 Warning 없애기 vi /etc/sysctl.conf 파일에 아래 추가 1 2 vm.overcommit_memory=1 fs.file-max = 1048576 vi /etc/rc.local 파일에 아래 추가 1 2 echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled sysctl -w net.","title":"redis 3.2.3 설치"},{"content":"최근에 윈도우 어플을 개발할 일이 생겼다.\n.NET 4.5부터 async 문법이 새로 들어갔다 해서.. 이왕 하는거 4.5.2로\u0026hellip; 만들기로 했다. 오\u0026hellip;\u0026hellip; 엄청나게 편리하다.!!\nasync, await 두개가 중요하다. 특히 UI프로그램에서 background thread와 main thread와의 동기화를 쉽게 지원한다.\n아래는 id/pwd를 입력받아서 서버통신으로 인증을 진행하는 코드다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 private async void btnLogin_Click(object sender, RoutedEventArgs e) { string id = tbEmail.Text; string pwd = tbPassword.Password; SetControlEnableState(false); bool isSuccess = await Task.Run\u0026lt;bool\u0026gt;(() =\u0026gt; { try { // 여기가 네트워크 통신을 하는 부분이다. _dataCore.DoLogin(id, pwd); return true; } catch (Exception x) { ErrorHandler.ErrorDump(x, true); return false; } }); if (!isSuccess) { SetControlEnableState(true); return; } } 보면 알겠지만 client이벤트에서 바로 \u0026hellip; 별도 쓰레드 동기화 없이.. 로그인 처리를 모두 완료했다.\n오늘 테스트를 진행하는데\u0026hellip; .NET Framework 4.5 깔린\u0026hellip; PC가.. 많이 없네\u0026hellip;..\n\u0026hellip; 그래서.. 4.0으로.. BackgroundWorker 사용해서 재개발했다\u0026hellip;\n그지 같네\u0026hellip; (화면이 세개인 프로그램이라 다행)\n","permalink":"https://kimpaper.github.io/posts/dotnet/2015-09-17-net-framework-452-40/","summary":"최근에 윈도우 어플을 개발할 일이 생겼다.\n.NET 4.5부터 async 문법이 새로 들어갔다 해서.. 이왕 하는거 4.5.2로\u0026hellip; 만들기로 했다. 오\u0026hellip;\u0026hellip; 엄청나게 편리하다.!!\nasync, await 두개가 중요하다. 특히 UI프로그램에서 background thread와 main thread와의 동기화를 쉽게 지원한다.\n아래는 id/pwd를 입력받아서 서버통신으로 인증을 진행하는 코드다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 private async void btnLogin_Click(object sender, RoutedEventArgs e) { string id = tbEmail.","title":".NET Framework 4.5.2로 개발했다가. 4.0로... 내림 "},{"content":"친구랑 개발하는 간단한 쪽지앱의 서버로 사용할 서버를 구축했다. 물론 나는 잘 모른다 모든건 다 구글을 통해..\n1. SWAP 메모리 할당 https://www.digitalocean.com/community/tutorials/how-to-add-swap-on-centos-6\n1 2 3 4 5 dd if=/dev/zero of=/swapfile bs=1024 count=2048k mkswap /swapfile swapon /swapfile chown root:root /swapfile chmod 0600 /swapfile 아래 내용을 /etc/fstab 에 붙인다.\n1 /swapfile swap swap defaults 0 0 2. 서버 시간을 KST 로 바꿈 \u0026amp; rdate 설치 1 2 ln -sf /usr/share/zoneinfo/Asia/Seoul /etc/localtime yum install rdate 3. java 1.7설치 rpm http://www.oracle.com/technetwork/java/javase/downloads/jre7-downloads-1880261.html 위에서 64비트 linux용으로 다운받는다.\n1 rpm -ivh jre-7u80-linux-x64.rpm 4. 위와 같은 방법으로 rabbitMQ 서버도 설치 1 2 rpm -ivh erlang-17.4-1.el6.x86_64.rpm rpm -ivh rabbitmq-server-3.4.4-1.noarch.rpm /etc/rabbitmq/rabbitmq-env.conf 파일 만들고 nodename 지정\n1 NODENAME=samplenode 관리자 페이지 플러그인 활성화 \u0026amp; 서버 시작\n1 2 rabbitmq-plugins enable rabbitmq_management rabbitmq-server -detached 사용자 추가, id/pwd 지정하기 권한 주기 참고) https://www.rabbitmq.com/man/rabbitmqctl.1.man.html#\n1 2 rabbitmqctl add_user {username} {password} rabbitmqctl set_user_tags {username} administrator http://hostname:15672/ 에 접속하여 admin메뉴에서 guest 계정 삭제 신규 worker 계정 추가\n5. tomcat 7 설치 tar 다운로드 하여 /usr/local/ 에 압축을 풀고.\n1 ln -s apache-tomcat-7.0.57 tomcat 6. mariadb 설치 http://zetawiki.com/wiki/%EB%A6%AC%EB%88%85%EC%8A%A4_MariaDB_%EC%84%A4%EC%B9%98 참고 아래 파일을 생성하고 내용을 작성 /etc/yum.repos.d/MariaDB.repoMariaDB.repo\n1 2 3 4 5 [mariadb] name = MariaDB baseurl = http://yum.mariadb.org/5.5/centos6-amd64 gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB gpgcheck=1 1 2 3 4 yum install MariaDB-server MariaDB-client #나중에 추가됨 (기본 설정 파일 적용) cp /usr/share/mysql/my-medium.cnf /etc/my.cnf 7. apache 설치 1 2 yum install httpd yum install mod_ssl 8. iptables 설정 아래 좋은 글이 있어 참고하여 아래와 같이 작성 했다. 출처) http://webdir.tistory.com/170\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/bin/bash # iptables 설정 자동화 스크립트 # 입맛에 따라 수정해서 사용합시다. iptables -F # TCP 포트 22번을 SSH 접속을 위해 허용 # 원격 접속을 위해 먼저 설정합니다 iptables -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT # 기본 정책을 설정합니다 iptables -P INPUT DROP iptables -P FORWARD DROP iptables -P OUTPUT ACCEPT # localhost 접속 허용 iptables -A INPUT -i lo -j ACCEPT # established and related 접속을 허용 iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT # 기타 사용하는 포트 허용 # -s xxx.xxx.xxx.xxx 를 추가 하여 특정 아이피만 가능하도록 할 수 있다. iptables -A INPUT -p tcp --dport 80 -j ACCEPT iptables -A INPUT -p tcp --dport 8080 -j ACCEPT iptables -A INPUT -p tcp --dport 443 -j ACCEPT iptables -A INPUT -p tcp --dport 3306 -j ACCEPT iptables -A INPUT -p tcp --dport 15672 -j ACCEPT # 설정을 저장 /sbin/service iptables save # 설정한 내용을 출력 iptables -L -v ","permalink":"https://kimpaper.github.io/posts/centos/2015-09-16-centos-67/","summary":"친구랑 개발하는 간단한 쪽지앱의 서버로 사용할 서버를 구축했다. 물론 나는 잘 모른다 모든건 다 구글을 통해..\n1. SWAP 메모리 할당 https://www.digitalocean.com/community/tutorials/how-to-add-swap-on-centos-6\n1 2 3 4 5 dd if=/dev/zero of=/swapfile bs=1024 count=2048k mkswap /swapfile swapon /swapfile chown root:root /swapfile chmod 0600 /swapfile 아래 내용을 /etc/fstab 에 붙인다.\n1 /swapfile swap swap defaults 0 0 2. 서버 시간을 KST 로 바꿈 \u0026amp; rdate 설치 1 2 ln -sf /usr/share/zoneinfo/Asia/Seoul /etc/localtime yum install rdate 3.","title":"디지탈오션에 서버 셋팅기 (centos 6.7)"},{"content":"최근에 spring-batch를 사용해 봤는데.. 결과는 성공적 특히 트랜잭션commit size와 read size를 따로 지정할 수 있다는게 좋은것 같다.\n쿼리나 기타 로직보다 아래 설정이 중요한 듯 하여 아래 설정을 기록으로 남긴다.\njob에 대해서 요약하면\nreader에서 데이타를 읽어서 process 에서 처리 하고 writer로 결과를 기록 한다.\n물론 위 설정 외에 각 시작 구간마다 이벤트를 받아 처리 할 수 있는 listener 같은 것도 제공한다.\nreader, writer는 커스텀 하지 않고 mybatis에서 기본으로 제공하는 걸 이용했다.\n참고) https://mybatis.github.io/spring/ko/batch.html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \u0026lt;bean id=\u0026#34;jobLauncher\u0026#34; class=\u0026#34;org.springframework.batch.core.launch.support.SimpleJobLauncher\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;jobRepository\u0026#34; ref=\u0026#34;jobRepository\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;jobRepository\u0026#34; class=\u0026#34;org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;transactionManager\u0026#34; ref=\u0026#34;transactionManager\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;!-- sent type sent --\u0026gt; \u0026lt;job:job id=\u0026#34;rstJob\u0026#34; job-repository=\u0026#34;jobRepository\u0026#34;\u0026gt; \u0026lt;job:step id=\u0026#34;step1\u0026#34;\u0026gt; \u0026lt;tasklet\u0026gt; \u0026lt;chunk reader=\u0026#34;rstReader\u0026#34; processor=\u0026#34;memberRstProcess\u0026#34; writer=\u0026#34;rstWriter\u0026#34; commit-interval=\u0026#34;500\u0026#34;\u0026gt; \u0026lt;/chunk\u0026gt; \u0026lt;/tasklet\u0026gt; \u0026lt;/job:step\u0026gt; \u0026lt;/job:job\u0026gt; \u0026lt;bean id=\u0026#34;memberRstProcess\u0026#34; class=\u0026#34;com.xxxxx.MemberRstProcess\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;rstReader\u0026#34; class=\u0026#34;org.mybatis.spring.batch.MyBatisPagingItemReader\u0026#34; p:sqlSessionFactory-ref=\u0026#34;sqlSessionFactory\u0026#34; p:queryId=\u0026#34;com.xxxxx.mapper.QueryMapper.selectMemberRstList\u0026#34; p:pageSize=\u0026#34;500\u0026#34; scope=\u0026#34;step\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;rstWriter\u0026#34; class=\u0026#34;org.mybatis.spring.batch.MyBatisBatchItemWriter\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;sqlSessionFactory\u0026#34; ref=\u0026#34;sqlSessionFactory\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;statementId\u0026#34; value=\u0026#34;com.xxxxx.mapper.QueryMapper.updateMemberRst\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; ","permalink":"https://kimpaper.github.io/posts/spring/2015-08-28-spring-batch/","summary":"최근에 spring-batch를 사용해 봤는데.. 결과는 성공적 특히 트랜잭션commit size와 read size를 따로 지정할 수 있다는게 좋은것 같다.\n쿼리나 기타 로직보다 아래 설정이 중요한 듯 하여 아래 설정을 기록으로 남긴다.\njob에 대해서 요약하면\nreader에서 데이타를 읽어서 process 에서 처리 하고 writer로 결과를 기록 한다.\n물론 위 설정 외에 각 시작 구간마다 이벤트를 받아 처리 할 수 있는 listener 같은 것도 제공한다.\nreader, writer는 커스텀 하지 않고 mybatis에서 기본으로 제공하는 걸 이용했다.","title":"spring batch 사용 "},{"content":"jfreeChart를 사용하는 중인데 tomcat위에서 돌리면 한글이 ㅁㅁㅁ 과 같이 나온다.\n/usr/share/fonts 폴더에 폰트파일을 넣고 fc-cache -fv 를 해주자!!\n1 2 3 4 5 6 7 8 // 코드 상에 아래와 같이 폰트를 지정한다. private static final Font _BASE_FONT = new Font(\u0026#34;나눔고딕\u0026#34;,Font.PLAIN,11); ... 중략 \u0026#39;\u0026#39;\u0026#39; // setFont를 적절하게 코드 내에 사용한다. lineAndShapeRenderer.setLegendTextFont(i, _BASE_FONT); ... tomcat 재시작은 필요 없다.\n","permalink":"https://kimpaper.github.io/posts/centos/2015-07-02-jfreechart-centos/","summary":"jfreeChart를 사용하는 중인데 tomcat위에서 돌리면 한글이 ㅁㅁㅁ 과 같이 나온다.\n/usr/share/fonts 폴더에 폰트파일을 넣고 fc-cache -fv 를 해주자!!\n1 2 3 4 5 6 7 8 // 코드 상에 아래와 같이 폰트를 지정한다. private static final Font _BASE_FONT = new Font(\u0026#34;나눔고딕\u0026#34;,Font.PLAIN,11); ... 중략 \u0026#39;\u0026#39;\u0026#39; // setFont를 적절하게 코드 내에 사용한다. lineAndShapeRenderer.setLegendTextFont(i, _BASE_FONT); ... tomcat 재시작은 필요 없다.","title":"jfreeChart에서 한글 폰트 사용 (centos 폰트 설정)"},{"content":"터미널 열고\n1 ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; 1 2 gimjonghuiui-MacBook-Pro:bin paper$ brew -v Homebrew 0.9.5 출처: http://coolestguidesontheplanet.com/installing-homebrew-os-x-yosemite-10-10-package-manager-unix-apps/\n","permalink":"https://kimpaper.github.io/posts/mac/2015-06-04-osx-10103-homebrew/","summary":"터미널 열고\n1 ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; 1 2 gimjonghuiui-MacBook-Pro:bin paper$ brew -v Homebrew 0.9.5 출처: http://coolestguidesontheplanet.com/installing-homebrew-os-x-yosemite-10-10-package-manager-unix-apps/","title":"OSX 10.10.3 homebrew 설치하기"},{"content":"context-hadoop.xml에 아래 내용 추가. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;hdp:configuration id=\u0026#34;hdConf\u0026#34;\u0026gt; fs.default.name=hdfs://localhost:9000 \u0026lt;/hdp:configuration\u0026gt; \u0026lt;hdp:job id=\u0026#34;wordCountJob\u0026#34; input-path=\u0026#34;/input/\u0026#34; output-path=\u0026#34;/output/\u0026#34; configuration-ref=\u0026#34;hdConf\u0026#34; mapper=\u0026#34;delim.app.service.WordCount$TokenizerMapper\u0026#34; reducer=\u0026#34;delim.app.service.WordCount$IntSumReducer\u0026#34; \u0026gt; \u0026lt;/hdp:job\u0026gt; \u0026lt;hdp:job-runner id=\u0026#34;wordCountJobRunner\u0026#34; job-ref=\u0026#34;wordCountJob\u0026#34; run-at-startup=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;/hdp:job-runner\u0026gt; WordCount.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapreduce.Mapper; import org.apache.hadoop.mapreduce.Reducer; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.io.IOException; import java.util.StringTokenizer; public class WordCount { private static final Logger logger = LoggerFactory.getLogger(WordCount.class); public static class TokenizerMapper extends Mapper\u0026lt;Object, Text, Text, IntWritable\u0026gt; { private final static IntWritable one = new IntWritable(1); private Text word = new Text(); @Override public void map(Object key, Text value, Context context) throws IOException, InterruptedException { logger.info(\u0026#34;map key={}, value={}\u0026#34;, key, value); StringTokenizer itr = new StringTokenizer(value.toString()); while (itr.hasMoreTokens()) { word.set(itr.nextToken()); context.write(word, one); } } } public static class IntSumReducer extends Reducer\u0026lt;Text, IntWritable, Text, IntWritable\u0026gt; { private IntWritable result = new IntWritable(); @Override public void reduce(Text key, Iterable\u0026lt;IntWritable\u0026gt; values, Context context) throws IOException, InterruptedException { logger.info(\u0026#34;reduce key={}\u0026#34;, key); int sum = 0; for (IntWritable val : values) { sum += val.get(); } result.set(sum); context.write(key, result); } } } Test.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Autowired private org.apache.hadoop.conf.Configuration hdConf; @Autowired private JobRunner wordCountJobRunner; @Before public void beforeCopyFile() throws IOException { String file = \u0026#34;/Users/paper/Desktop/4/14/debug.2015-04-09.log\u0026#34;; Path srcFilePath = new Path(file); Path dstFilePath = new Path(\u0026#34;/input/debug.2015-04-09.log\u0026#34;); FileSystem hdfs = FileSystem.get(dstFilePath.toUri(), hdConf); hdfs.copyFromLocalFile(false, true, srcFilePath, dstFilePath); hdfs.delete(new Path(\u0026#34;/output/\u0026#34;), true); } @Test public void testRunJob() throws Exception { wordCountJobRunner.call(); } Before를 통하여 로컬에 있는 debug.log 파일을 hdfs에 카피 해놓는다. Job을 실행한다. 실행하면 debug.log 파일을 line단위로 읽어들이는걸 확인 할 수 있다. (WordCount$TokenizerMapper) ","permalink":"https://kimpaper.github.io/2015/04/15/2-hadoop-26x-with-spring-40-mapreduce/","summary":"context-hadoop.xml에 아래 내용 추가. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;hdp:configuration id=\u0026#34;hdConf\u0026#34;\u0026gt; fs.default.name=hdfs://localhost:9000 \u0026lt;/hdp:configuration\u0026gt; \u0026lt;hdp:job id=\u0026#34;wordCountJob\u0026#34; input-path=\u0026#34;/input/\u0026#34; output-path=\u0026#34;/output/\u0026#34; configuration-ref=\u0026#34;hdConf\u0026#34; mapper=\u0026#34;delim.app.service.WordCount$TokenizerMapper\u0026#34; reducer=\u0026#34;delim.app.service.WordCount$IntSumReducer\u0026#34; \u0026gt; \u0026lt;/hdp:job\u0026gt; \u0026lt;hdp:job-runner id=\u0026#34;wordCountJobRunner\u0026#34; job-ref=\u0026#34;wordCountJob\u0026#34; run-at-startup=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;/hdp:job-runner\u0026gt; WordCount.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 import org.","title":"하둡 스프링 연동 테스트2 - hadoop 2.6.x with spring 4.0 (MapReduce WordCount example)"},{"content":"Hadoop 설치 및 설정은 아래와 같이 (osx 요세미티.) https://hadoop.apache.org/releases.html#Download ( 2.6.x 버전 )\n설치는 아래 블로그 보고 함 http://iamhereweare.blogspot.kr/2014/05/hadoop.html\npom.xml 에 아래 dependency 추가. 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupid\u0026gt;org.springframework.data\u0026lt;/groupId\u0026gt; \u0026lt;artifactid\u0026gt;spring-data-hadoop\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; context-hadoop.xml spring 설정에 파일 추가 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:hdp=\u0026#34;http://www.springframework.org/schema/hadoop\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/hadoop http://www.springframework.org/schema/hadoop/spring-hadoop.xsd\u0026#34;\u0026gt; \u0026lt;hdp:configuration id=\u0026#34;hdConf\u0026#34;\u0026gt; fs.default.name=hdfs://localhost:9000 \u0026lt;/hdp:configuration\u0026gt; \u0026lt;/beans\u0026gt; 아래와 같이 test코드 작성.\nHdTestServiceTest.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration({ \u0026#34;classpath:servlet-context.xml\u0026#34;, \u0026#34;classpath:config/context-datasource.xml\u0026#34;, \u0026#34;classpath:config/context-hadoop.xml\u0026#34; }) public class HdTestServiceTest { private static final Logger logger = LoggerFactory.getLogger(HdTestService.class); @Autowired private org.apache.hadoop.conf.Configuration hdConf; @Test public void testDoTest() throws Exception { FileSystem hdfs = null; try { Path filePath = new Path(\u0026#34;/tmp/test.txt\u0026#34;); logger.info(\u0026#34;filePath.uri={}\u0026#34;, filePath.toUri()); hdfs = FileSystem.get(filePath.toUri(), hdConf); if(hdfs.exists(filePath)) { logger.info(\u0026#34;read file path={}\u0026#34;, filePath); BufferedReader r = new BufferedReader(new InputStreamReader(hdfs.open(filePath), \u0026#34;utf-8\u0026#34;)); String line = null; do { line = r.readLine(); logger.info(\u0026#34; line={}\u0026#34;, line); } while(line != null); r.close(); // dfs.delete(filePath, true); } else { logger.info(\u0026#34;create new file path={}\u0026#34;, filePath); FSDataOutputStream out = hdfs.create(filePath, false); out.write(\u0026#34;한글 생성 테스트\u0026#34;.getBytes(\u0026#34;utf-8\u0026#34;)); out.flush(); out.close(); } } finally { IOUtils.closeQuietly(hdfs); } } } 잘된다. 다만 아직 로컬에서 못벗어 났지만.. 벗어날 서버가 없어..\n위 코드를 이용하면 파일 업로드 다운로드까지는 구현이 가능합니다.\n","permalink":"https://kimpaper.github.io/2015/04/12/hadoop-26x-with-spring-40/","summary":"Hadoop 설치 및 설정은 아래와 같이 (osx 요세미티.) https://hadoop.apache.org/releases.html#Download ( 2.6.x 버전 )\n설치는 아래 블로그 보고 함 http://iamhereweare.blogspot.kr/2014/05/hadoop.html\npom.xml 에 아래 dependency 추가. 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupid\u0026gt;org.springframework.data\u0026lt;/groupId\u0026gt; \u0026lt;artifactid\u0026gt;spring-data-hadoop\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; context-hadoop.xml spring 설정에 파일 추가 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:hdp=\u0026#34;http://www.springframework.org/schema/hadoop\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/hadoop http://www.springframework.org/schema/hadoop/spring-hadoop.xsd\u0026#34;\u0026gt; \u0026lt;hdp:configuration id=\u0026#34;hdConf\u0026#34;\u0026gt; fs.default.name=hdfs://localhost:9000 \u0026lt;/hdp:configuration\u0026gt; \u0026lt;/beans\u0026gt; 아래와 같이 test코드 작성.","title":"하둡 스프링 연동 테스트 - hadoop 2.6.x with spring 4.0"},{"content":"이것저것 했는데 403이 계속 나오면..\n1 chcon -R --reference=/var/www /www/webroot 또는\n1 chcon -R -h -t httpd_sys_content_t /www/webroot ","permalink":"https://kimpaper.github.io/posts/centos/2015-03-27-403/","summary":"이것저것 했는데 403이 계속 나오면..\n1 chcon -R --reference=/var/www /www/webroot 또는\n1 chcon -R -h -t httpd_sys_content_t /www/webroot ","title":"아파치에서 403 오류 나올때."},{"content":"pom.xml에 아래 추가. 1 2 3 4 5 6 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-test\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.5.RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; test java코드 MemberServiceTest.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( { \u0026#34;classpath:servlet-context.xml\u0026#34;, \u0026#34;classpath:config/context-datasource.xml\u0026#34; } ) public class MemberServiceTest { @Autowired MemberService memberService; @Test public void testSr2002() throws Exception { RequestData req = new RequestData(null, new DbMap()); ResponseData res = new ResponseData(new DbMap()); memberService.sr2002(req, res); } } 이때 디비를 jndi-lookup 를 이용하는 경우를 위해 test/resources/config/context-datasource.xml 을 넣어서 아래와 같이 기존 id를 덮었다.\ntest/resources/config/context-datasource.xml 파일 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:p=\u0026#34;http://www.springframework.org/schema/p\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;dataSource\u0026#34; class=\u0026#34;org.springframework.jdbc.datasource.DriverManagerDataSource\u0026#34; p:driverClassName=\u0026#34;com.mysql.jdbc.Driver\u0026#34; p:url=\u0026#34;jdbc:mysql://server:3306/dbname\u0026#34; p:username=\u0026#34;sa\u0026#34; p:password=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; ","permalink":"https://kimpaper.github.io/posts/spring/2015-03-25-spring-junit-testcase/","summary":"pom.xml에 아래 추가. 1 2 3 4 5 6 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-test\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.5.RELEASE\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; test java코드 MemberServiceTest.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration( { \u0026#34;classpath:servlet-context.xml\u0026#34;, \u0026#34;classpath:config/context-datasource.xml\u0026#34; } ) public class MemberServiceTest { @Autowired MemberService memberService; @Test public void testSr2002() throws Exception { RequestData req = new RequestData(null, new DbMap()); ResponseData res = new ResponseData(new DbMap()); memberService.","title":"spring junit testcase 작성"},{"content":"설치는 그냥 rpm 으로 설치 1 2 3 4 5 # 서버 시작. sbin/rabbitmq-server start # 서버 중지 sbin/rabbitmqctl stop spring-rabbit 연동 pom.xml 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupid\u0026gt;org.springframework.amqp\u0026lt;/groupId\u0026gt; \u0026lt;artifactid\u0026gt;spring-rabbit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; context-rabbitmq.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!-- A reference to the org.springframework.amqp.rabbit.connection.ConnectionFactory --\u0026gt; \u0026lt;rabbit:connection-factory id=\u0026#34;connectionFactory\u0026#34; host=\u0026#34;localhost\u0026#34; username=\u0026#34;worker\u0026#34; password=\u0026#34;workerpassword\u0026#34; /\u0026gt; \u0026lt;!-- Creates a org.springframework.amqp.rabbit.core.RabbitTemplate for access to the broker --\u0026gt; \u0026lt;rabbit:template id=\u0026#34;amqpTemplate\u0026#34; connection-factory=\u0026#34;connectionFactory\u0026#34; /\u0026gt; \u0026lt;!-- Creates a org.springframework.amqp.rabbit.core.RabbitAdmin to manage exchanges, queues and bindings --\u0026gt; \u0026lt;rabbit:admin connection-factory=\u0026#34;connectionFactory\u0026#34; /\u0026gt; \u0026lt;!-- Creates a queue for consumers to retrieve messages --\u0026gt; \u0026lt;rabbit:queue name=\u0026#34;simple_queue\u0026#34; /\u0026gt; \u0026lt;rabbit:listener-container connection-factory=\u0026#34;connectionFactory\u0026#34;\u0026gt; \u0026lt;rabbit:listener queues=\u0026#34;simple_queue\u0026#34; ref=\u0026#34;mqService\u0026#34; /\u0026gt; \u0026lt;/rabbit:listener-container\u0026gt; MqService.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Service public class MqService implements MessageListener { private static final Logger logger = LoggerFactory.getLogger(MqService.class); private static final String TASK_QUEUE_NAME = \u0026#34;simple_queue\u0026#34;; @Autowired private RabbitTemplate rabbitTemplate; public void send(String message) throws IOException { rabbitTemplate.convertAndSend(TASK_QUEUE_NAME, message); logger.info(\u0026#34;send message={}\u0026#34;, message); } @Override public void onMessage(Message message) { String msg = null; try { msg = new String(message.getBody(), \u0026#34;UTF-8\u0026#34;); } catch (UnsupportedEncodingException e) { e.printStackTrace(); } logger.info(\u0026#34;recv message=\u0026#34; + msg ); } } ","permalink":"https://kimpaper.github.io/posts/spring/2015-03-11-spring-rabbitmq/","summary":"설치는 그냥 rpm 으로 설치 1 2 3 4 5 # 서버 시작. sbin/rabbitmq-server start # 서버 중지 sbin/rabbitmqctl stop spring-rabbit 연동 pom.xml 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupid\u0026gt;org.springframework.amqp\u0026lt;/groupId\u0026gt; \u0026lt;artifactid\u0026gt;spring-rabbit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; context-rabbitmq.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!-- A reference to the org.springframework.amqp.rabbit.connection.ConnectionFactory --\u0026gt; \u0026lt;rabbit:connection-factory id=\u0026#34;connectionFactory\u0026#34; host=\u0026#34;localhost\u0026#34; username=\u0026#34;worker\u0026#34; password=\u0026#34;workerpassword\u0026#34; /\u0026gt; \u0026lt;!-- Creates a org.springframework.amqp.rabbit.core.RabbitTemplate for access to the broker --\u0026gt; \u0026lt;rabbit:template id=\u0026#34;amqpTemplate\u0026#34; connection-factory=\u0026#34;connectionFactory\u0026#34; /\u0026gt; \u0026lt;!","title":"spring-rabbitmq 연동 "},{"content":"svn to git 마이그레이션 1 2 git svn clone --stdlayout --no-metadata -A users.txt svn://example.com/repository/projectname cd projectname 아래 users.txt 만드는건데 perl 이 없어서 그런지.. 안되네요\u0026hellip; ㅠ\nsvn log ^/ --xml | grep -P \u0026quot;^\u0026lt;author\u0026quot; | sort -u | \\ perl -pe 's/\u0026lt;author\u0026gt;(.*?)\u0026lt;\\/author\u0026gt;/$1 = /' \u0026gt; users.txt\nignore file처리 1 git svn show-ignore -i trunk \u0026gt; .gitignore remote git 지정 1 git remote add origin git@git.example.com:group/projectname.git tags 처리 1 git for-each-ref refs/remotes/tags | cut -d / -f 4- | grep -v @ | while read tagname; do git tag \u0026#34;$tagname\u0026#34; \u0026#34;tags/$tagname\u0026#34;; git branch -r -d \u0026#34;tags/$tagname\u0026#34;; done branches 처리 1 git for-each-ref refs/remotes | cut -d / -f 3- | grep -v @ | while read branchname; do git branch \u0026#34;$branchname\u0026#34; \u0026#34;refs/remotes/$branchname\u0026#34;; git branch -r -d \u0026#34;$branchname\u0026#34;; done push한다. 1 2 git push origin --all git push origin --tags revert local commit 1 git reset —hard remotes/origin/HEAD backup 1 sudo gitlab-rake gitlab:backup:create restore (가장 최근꺼 복원) 1 sudo gitlab-rake gitlab:backup:restore restore OPTION (아래 지정한 타임스탬프로 복원시켜준다는건가.. 안해봄..)\nBACKUP=timestamp_of_backup (required if more than one backup exists)\n","permalink":"https://kimpaper.github.io/posts/centos/2015-03-05-git/","summary":"svn to git 마이그레이션 1 2 git svn clone --stdlayout --no-metadata -A users.txt svn://example.com/repository/projectname cd projectname 아래 users.txt 만드는건데 perl 이 없어서 그런지.. 안되네요\u0026hellip; ㅠ\nsvn log ^/ --xml | grep -P \u0026quot;^\u0026lt;author\u0026quot; | sort -u | \\ perl -pe 's/\u0026lt;author\u0026gt;(.*?)\u0026lt;\\/author\u0026gt;/$1 = /' \u0026gt; users.txt\nignore file처리 1 git svn show-ignore -i trunk \u0026gt; .gitignore remote git 지정 1 git remote add origin git@git.example.com:group/projectname.git tags 처리 1 git for-each-ref refs/remotes/tags | cut -d / -f 4- | grep -v @ | while read tagname; do git tag \u0026#34;$tagname\u0026#34; \u0026#34;tags/$tagname\u0026#34;; git branch -r -d \u0026#34;tags/$tagname\u0026#34;; done branches 처리 1 git for-each-ref refs/remotes | cut -d / -f 3- | grep -v @ | while read branchname; do git branch \u0026#34;$branchname\u0026#34; \u0026#34;refs/remotes/$branchname\u0026#34;; git branch -r -d \u0026#34;$branchname\u0026#34;; done push한다.","title":"git 관련 명령어 모음"},{"content":"1. 현재 설정된 상태 확인 1 2 3 4 5 6 7 8 9 10 11 12 13 MariaDB [(none)]\u0026gt; show variables like \u0026#34;%character%\u0026#34;;show variables like \u0026#34;%collation%\u0026#34;; +--------------------------+---------------------------------+ | Variable_name | Value | +--------------------------+---------------------------------+ | character_set_client | utf8 | | character_set_connection | utf8 | | character_set_database | utf8 | | character_set_filesystem | binary | | character_set_results | utf8 | | character_set_server | utf8 | | character_set_system | utf8 | | character_sets_dir | /usr/local/mysql/share/charsets/| +--------------------------+---------------------------------+ 2. sudo vi /etc/my.cnf 파일을 아래 부분 수정 1 2 3 4 5 6 7 8 9 [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 [mysqld] collation-server = utf8mb4_unicode_ci character-set-server = utf8mb4 3. 서비스 재시작 1 service mysql restart 4. 확인 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 MariaDB [(none)]\u0026gt; show variables like \u0026#34;%character%\u0026#34;;show variables like \u0026#34;%collation%\u0026#34;; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8mb4 | | character_set_connection | utf8mb4 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | utf8mb4 | | character_set_server | utf8mb4 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.00 sec) +----------------------+--------------------+ | Variable_name | Value | +----------------------+--------------------+ | collation_connection | utf8mb4_general_ci | | collation_database | utf8mb4_unicode_ci | | collation_server | utf8mb4_unicode_ci | +----------------------+--------------------+ 3 rows in set (0.00 sec) 마지막으로 실제 적용할 컬럼의 타입을 바꿔야 한다.\nutf8mb4로 바꿔야 합니다.\n","permalink":"https://kimpaper.github.io/posts/centos/2015-02-11-mysql-mariadb-utf8mb4/","summary":"1. 현재 설정된 상태 확인 1 2 3 4 5 6 7 8 9 10 11 12 13 MariaDB [(none)]\u0026gt; show variables like \u0026#34;%character%\u0026#34;;show variables like \u0026#34;%collation%\u0026#34;; +--------------------------+---------------------------------+ | Variable_name | Value | +--------------------------+---------------------------------+ | character_set_client | utf8 | | character_set_connection | utf8 | | character_set_database | utf8 | | character_set_filesystem | binary | | character_set_results | utf8 | | character_set_server | utf8 | | character_set_system | utf8 | | character_sets_dir | /usr/local/mysql/share/charsets/| +--------------------------+---------------------------------+ 2.","title":"mysql, mariadb에서 유니코드(utf8mb4) 지원하기"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #프로그램 설치위치 찾기 which java /usr/bin/java #오래된 로그파일만 찾아서 삭제함 find /logs/httpd/ -type f -mtime +180 -exec rm -f {} \\; #hosts 편집 vi /etc/hosts #dns서버 수정 vi /etc/resolv.conf #OS 비트 확인 getconf LONG_BIT #OS 버전 확인 cat /etc/issue #폰트목록 fc-list #폰트 반영 (/usr/share/fonts 에 폰트 넣고) fc-cache -fv #로그보기 tail -f file.log -n 1000 #crond 명령 # 목록보기 crontab -l # 편집 crontab -e # 톰켓 프로세스 확인 ps -ef | grep tomcat # 프로세스 kill kill -9 {PID} ","permalink":"https://kimpaper.github.io/posts/centos/2015-02-06-blog-post_21/","summary":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #프로그램 설치위치 찾기 which java /usr/bin/java #오래된 로그파일만 찾아서 삭제함 find /logs/httpd/ -type f -mtime +180 -exec rm -f {} \\; #hosts 편집 vi /etc/hosts #dns서버 수정 vi /etc/resolv.conf #OS 비트 확인 getconf LONG_BIT #OS 버전 확인 cat /etc/issue #폰트목록 fc-list #폰트 반영 (/usr/share/fonts 에 폰트 넣고) fc-cache -fv #로그보기 tail -f file.","title":"CentOS 명령어 모음"},{"content":"8버전부터 11버전까지 아래 셋팅을 이용하여 사용 중입니다.\n1. 키보드 설정에서 \u0026ldquo;이전 입력 소스 선택\u0026quot;이랑 \u0026ldquo;입력 메뉴에서 다음 소스 선택\u0026quot;을 서로 단축키를 바꿈 2. 페러럴즈 환경설정에서 아래 단축키를 매핑추가함 (Command+Space -\u0026gt; AltGr) 끝. 위와 같이 했더니 저는 됬어요.\n","permalink":"https://kimpaper.github.io/posts/mac/2015-02-06-parallels-8-9-commandspace/","summary":"8버전부터 11버전까지 아래 셋팅을 이용하여 사용 중입니다.\n1. 키보드 설정에서 \u0026ldquo;이전 입력 소스 선택\u0026quot;이랑 \u0026ldquo;입력 메뉴에서 다음 소스 선택\u0026quot;을 서로 단축키를 바꿈 2. 페러럴즈 환경설정에서 아래 단축키를 매핑추가함 (Command+Space -\u0026gt; AltGr) 끝. 위와 같이 했더니 저는 됬어요.","title":"Parallels에서 Command+Space로 한영변환 하기"},{"content":"항상 json으로만 뱉다가 xml로 뱉어야 하는 상황이 발생해서 만든 spring view 클래스\n결과가 map에 경우에만 해당됨\n아래 설정하고\u0026hellip;\napplicationServlet.xml 1 2 3 4 \u0026lt;beans:bean id=\u0026#34;xmlView2\u0026#34; class=\u0026#34;org.springframework.web.servlet.view.XmlViewResolver\u0026#34;\u0026gt; \u0026lt;beans:property name=\u0026#34;order\u0026#34; value=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;beans:property name=\u0026#34;location\u0026#34; value=\u0026#34;classpath:xml-views.xml\u0026#34;/\u0026gt; \u0026lt;/beans:bean\u0026gt; xml-views.xml 내용. 1 2 3 4 5 6 7 8 9 10 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE beans PUBLIC \u0026#34;-//SPRING//DTD BEAN//EN\u0026#34; \u0026#34;http://www.springframework.org/dtd/spring-beans.dtd\u0026#34;\u0026gt; \u0026lt;beans\u0026gt; \u0026lt;bean name=\u0026#34;xmlView\u0026#34; class=\u0026#34;com.xxxxx.view.AjaxResponseXMLView\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;contentType\u0026#34;\u0026gt; \u0026lt;value\u0026gt;text/xml;charset=utf-8\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; AjaxResponseXMLView.java 아래 클래스를 이용함 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 public class AjaxResponseXMLView extends AbstractView { @Override protected void renderMergedOutputModel(Map map, HttpServletRequest request, HttpServletResponse response) throws Exception { String xmlHeader = \u0026#34;\\r\\n\u0026#34;; StringBuffer xmlSb = new StringBuffer(); xmlSb.append(xmlHeader); xmlSb.append(\u0026#34;\u0026#34;); writeFromMap(xmlSb, map); xmlSb.append(\u0026#34;\u0026#34;); response.setContentType(\u0026#34;application/xml\u0026#34;); response.setCharacterEncoding(\u0026#34;utf-8\u0026#34;); response.setHeader(\u0026#34;Cache-Control\u0026#34;, \u0026#34;no-cache\u0026#34;); response.setContentLength(xmlSb.toString().getBytes(\u0026#34;utf-8\u0026#34;).length); response.getWriter().print(xmlSb.toString()); } private void writeFromMap(StringBuffer sb, Map map) { for(Object str : map.keySet()) { Object v = map.get(str); sb.append(\u0026#34;\u0026lt;\u0026#34; + str + \u0026#34;\u0026gt;\u0026#34;); if(v instanceof Map) { writeFromMap(sb, (Map) v); } else if(v instanceof List) { writeFromList(sb, (List) v); } else { writeFromData(sb, v); } sb.append(\u0026#34;\u0026lt;/\u0026#34; + str + \u0026#34;\u0026gt;\u0026#34;); } } private void writeFromList(StringBuffer sb, List list) { for(Object v : list) { sb.append(\u0026#34;\u0026#34;); if(v instanceof Map) { writeFromMap(sb, (Map)v); } else if(v instanceof List) { writeFromList(sb, (List) v); } else { writeFromData(sb, v); } sb.append(\u0026#34;\u0026#34;); } } private void writeFromData(StringBuffer sb, Object data) { sb.append(escapeXml(data+\u0026#34;\u0026#34;)); } private String escapeXml(String src) { // \u0026#34; \u0026#34; // \u0026lt; \u0026lt; // \u0026gt; \u0026gt; // \u0026amp; \u0026amp; src = src.replace(\u0026#34;\\\u0026#34;\u0026#34;, \u0026#34;\u0026#34;\u0026#34;); src = src.replace(\u0026#34;\u0026lt;\u0026#34;, \u0026#34;\u0026lt;\u0026#34;); src = src.replace(\u0026#34;\u0026gt;\u0026#34;, \u0026#34;\u0026gt;\u0026#34;); src = src.replace(\u0026#34;\u0026amp;\u0026#34;, \u0026#34;\u0026amp;\u0026#34;); return src; } } ","permalink":"https://kimpaper.github.io/posts/spring/2015-02-06-spring-map-to-xml-viewresolver/","summary":"항상 json으로만 뱉다가 xml로 뱉어야 하는 상황이 발생해서 만든 spring view 클래스\n결과가 map에 경우에만 해당됨\n아래 설정하고\u0026hellip;\napplicationServlet.xml 1 2 3 4 \u0026lt;beans:bean id=\u0026#34;xmlView2\u0026#34; class=\u0026#34;org.springframework.web.servlet.view.XmlViewResolver\u0026#34;\u0026gt; \u0026lt;beans:property name=\u0026#34;order\u0026#34; value=\u0026#34;1\u0026#34;/\u0026gt; \u0026lt;beans:property name=\u0026#34;location\u0026#34; value=\u0026#34;classpath:xml-views.xml\u0026#34;/\u0026gt; \u0026lt;/beans:bean\u0026gt; xml-views.xml 내용. 1 2 3 4 5 6 7 8 9 10 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE beans PUBLIC \u0026#34;-//SPRING//DTD BEAN//EN\u0026#34; \u0026#34;http://www.springframework.org/dtd/spring-beans.dtd\u0026#34;\u0026gt; \u0026lt;beans\u0026gt; \u0026lt;bean name=\u0026#34;xmlView\u0026#34; class=\u0026#34;com.xxxxx.view.AjaxResponseXMLView\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;contentType\u0026#34;\u0026gt; \u0026lt;value\u0026gt;text/xml;charset=utf-8\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; AjaxResponseXMLView.java 아래 클래스를 이용함 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 public class AjaxResponseXMLView extends AbstractView { @Override protected void renderMergedOutputModel(Map map, HttpServletRequest request, HttpServletResponse response) throws Exception { String xmlHeader = \u0026#34;\\r\\n\u0026#34;; StringBuffer xmlSb = new StringBuffer(); xmlSb.","title":"spring map to xml viewresolver"},{"content":"catalina.sh 맨 상위에 아래를 추가해서 메모리를 크게 잡자. (주의 서버 메모리를 생각해서 적당히. ) 1 export CATALINA_OPTS=\u0026#34;-Djava.awt.headless=true -server -Xms2048m -Xmx2048m -XX:NewSize=256m -XX:MaxNewSize=256m -XX:PermSize=256m -XX:MaxPermSize=512m -XX:+CMSClassUnloadingEnabled -XX:+CMSPermGenSweepingEnabled\u0026#34; 참고) http://stackoverflow.com/questions/88235/dealing-with-java-lang-outofmemoryerror-permgen-space-error\n","permalink":"https://kimpaper.github.io/posts/centos/2015-02-06-tomcat-outofmemory/","summary":"catalina.sh 맨 상위에 아래를 추가해서 메모리를 크게 잡자. (주의 서버 메모리를 생각해서 적당히. ) 1 export CATALINA_OPTS=\u0026#34;-Djava.awt.headless=true -server -Xms2048m -Xmx2048m -XX:NewSize=256m -XX:MaxNewSize=256m -XX:PermSize=256m -XX:MaxPermSize=512m -XX:+CMSClassUnloadingEnabled -XX:+CMSPermGenSweepingEnabled\u0026#34; 참고) http://stackoverflow.com/questions/88235/dealing-with-java-lang-outofmemoryerror-permgen-space-error","title":"tomcat 에서 OutOfMemory 자주 나오면."}]